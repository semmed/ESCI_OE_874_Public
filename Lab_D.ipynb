{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" width=\"12%\" style=\"padding-right:10px;\" src=\"./Images/Ccom.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Seabed Mapping Systems <a href=\"https://teams.microsoft.com/l/channel/19%3a6d420007fb504c57850639e54a52945b%40thread.tacv2/Lab%2520D?groupId=b7209537-725b-40fc-bdbe-212e9689ef18&tenantId=d6241893-512d-46dc-8d2b-be47e25f5666\"><img src=\"./Images/help.png\"  title=\"Ask questions on Teams\" align=\"right\" width=\"10%\" ></a><br><br>  Lab D: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D0 Create Python Script - Load the Dependecies\n",
    "\n",
    "We will run this lab a little different. Rather than adding and editing code in this Notebook we will use a script that we will run. This has the advantage that we ensure that all the code is executed sequentially. It also highlights another capability of Jupyter Notebooks.\n",
    "\n",
    "Create a LabD.py File and load the dependencies \n",
    "\n",
    "    # D0 Create Python Script - Load the Dependecies\n",
    "\n",
    "    import sys\n",
    "    import import_ipynb\n",
    "    import os.path\n",
    "    import matplotlib as plt\n",
    "    import numpy as np\n",
    "    from datetime import datetime, timedelta\n",
    "    from numpy import pi, arctan2, arccos, abs, sin, cos, tan, sqrt, sum, arctan\n",
    "    from mycode.position import Position\n",
    "    from mycode.twtt import TWTT\n",
    "    from mycode.integration import Integration\n",
    "    from mycode.integration import Motion\n",
    "    from datetime import datetime, timezone\n",
    "    from mycode.vessel import Vessel\n",
    "    from mycode.ssp import SSP\n",
    "    from mycode.ping import Ping\n",
    "    from mycode.om_math import Rx, Ry, Rz\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D0.1 Add the Current Folder To the Path\n",
    "\n",
    "Before we start in earnest we will have to do some more house keeping, we need to add the current folder to the path\n",
    "\n",
    "    # D0.1 Add the Current Folder To the Path\n",
    "\n",
    "    sys.path.append(os.getcwd())\n",
    "    abs_path=os.path.abspath(os.path.curdir)\n",
    "    print(\"Configured environment for Lab D\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D0.2 Testing, Testing, D0.1, D0.2\n",
    "\n",
    "In the code cell below we should see whether things worked\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%run -i LabD.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D1 Defining the Vessel\n",
    "\n",
    "<img align=\"center\" width=\"80%\" style=\"padding-right:10px;\" src=\"./Images/conecone.jpg\">\n",
    "\n",
    "In Lab A we saw that to obtain a location and orientation of the sonars (from which to calculate their sonar-relative beam vectors) we need to utilize asynchronous observations of position and orientation. They are both available on the vessel, but at different locations or orientations. To relate the two together, we needed to establish a ship reference frame.\n",
    "\n",
    "Within that reference frame we needed to establish the location and orientation of each sensor in turn. The net result is that we know the location of the transmit-transducer at the transmit epochs and the receive-transducer at the receive epochs.\n",
    "\n",
    "The data presented here is from the same expedition as that presented in Lab A, i.e. the vessel data is the same\n",
    "In the `LabD.py` script add the following to define the a `Vessel` object name `vessel`\n",
    "\n",
    "    vessel = Vessel()\n",
    "    vessel.metadata[\"name\"]=\"USNS Henson\"\n",
    "    vessel.metadata[\"owned_by\"]=\"United States Navy\"\n",
    "    vessel.metadata[\"operated_by\"]=\"United States Navy\"\n",
    "    vessel.metadata[\"pos_source\"]=\"NavCom (C-Nav)\"\n",
    "    vessel.metadata[\"sonar\"]=\"Kongsberg EM710\"\n",
    "    vessel.metadata[\"mru\"]=\"Applanix POS/MV 320\"\n",
    "    vessel.metadata[\"loa\"]=100\n",
    "    \n",
    "Also add the lever arms and water line\n",
    "\n",
    "    vessel.wl = -2.59\n",
    "    vessel.lever_arm_trans = np.asarray([16.26, -1.75, 4.15]).reshape((3, 1))\n",
    "    vessel.lever_arm_rec = np.array([14.82, -2.01, 4.17]).reshape((3, 1))\n",
    "    vessel.lever_arm_pos = np.array([-5.73, -0.12, -30.00]).reshape((3, 1))\n",
    "    vessel.lever_arm_mru = np.array([0, 0, 0]).reshape((3, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vessel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/ESCI_OE_874_Clean/LabD.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'run'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-i LabD.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvessel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'vessel' is not defined"
     ]
    }
   ],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(vessel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D2 Representing the Transmit and Receive Array\n",
    "\n",
    "For the directions it is helpful to represent the transducer arrays by unit vectors. Unit vectors have the unique property that the elements are the direction cosines with respect to the axis. We could proof this formally, but \n",
    "we will illustrate this at the hand of an example: the vector (1,1) has an angle of $1/4 \\pi$ radians and a length of $\\sqrt{2}$ Thus if we normalize the vector we end up with a vector $\\left(\\sqrt{2},\\sqrt{2}\\right)$ which has norm $1$. Similarly the $\\cos(1/4 \\pi) = \\sqrt{2}$. \n",
    "\n",
    "Thus it is very convenient to represent direction using unit vectors, the elements are direct measures of the angle that the vector makes with the coordinate axes. i.e. the first element represents the cosine of the angle of the vector with the first coordinate axis, the 2nd with the 2nd axis, etc.\n",
    "\n",
    "We will chose some directions of convenience - ideally the transmit transducer is aligned to the X-axis of a vessel thus a logical vector to represent its orientation is (1,0,0), ( the angle with the x-axis is zero, thus the first element is cos(0) = 1, the angle with the y- and z-axes is 90 degrees cos(90) = 0 thus our vector is (1, 0, 0)\n",
    "\n",
    "We will represent the ideal transmit and receive transducers with the variable `tx_ideal` and `rx_ideal` respectively\n",
    "\n",
    "In the `LabD.py` script add and complete the following \n",
    "\n",
    "    tx_ideal = np.array([[1],[0],[0]])\n",
    "    rx_ideal = np.array([...])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print( tx_ideal)\n",
    "print( rx_ideal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Configured environment for Lab D\n",
    "    [[1]\n",
    "     [0]\n",
    "     [0]]\n",
    "    [[0]\n",
    "     [1]\n",
    "     [0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D2.0 Representing the Transmit and Receive Array - Reality is Not Ideal\n",
    "\n",
    "Unfortunately reality is not ideal. The transducer will not be mounted quite orthogonal and not quite aligned to the vessel reference frame. We will have to deal with some mount angles that are deviations from the ideal vectors. In the case of the 'Henderson' these are known, so we may take them into account.\n",
    "\n",
    "In the `LabD.py` script add the following: \n",
    "\n",
    "    ma_tx=np.array([0.127,1.024,359.957-360])*pi/180  # Tx Mount angles \n",
    "    ma_rx=np.array([0.101,0.894,0.065])*pi/180    # Rx Mount angles \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print( ma_tx)\n",
    "print( ma_rx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Configered environment for Lab D\n",
    "    [ 0.00221657  0.01787217 -0.00075049]\n",
    "    [0.00176278 0.01560324 0.00113446]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D3 Parameters for Beam Forming\n",
    "\n",
    "In our case we will be reading data from a datagram collected with the Kongsberg system - all the data associated to the specific beam for the specific ping that we are interested in is contained in the data file `data_ping_4170.txt` that you may find in your `Data` folder.\n",
    "\n",
    "In our particular case you will be analyzing beam 391, we will keep track of that here so that you may later on extract the right information for the beam depression angle. We will also give you the sound speed at the transducer here, as you should not use the sound speed from the sound speed profile for that - that would create a significant error in your ray tracing.\n",
    "\n",
    "In the `LabD.py` script add the following:\n",
    "    ss_tx=1543.7                       \n",
    "    beam_select=391   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print( ss_tx)\n",
    "print( beam_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Configured environment for Lab D\n",
    "    1543.7\n",
    "    391\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D4 Get the Positioning Data\n",
    "\n",
    "We will get the positioning data and store them in a `Position` object called `positions`. We will do this in the same fashion as in Lab A - the data file is called `Lab_A_GNSS.txt` is located in the Data folder, should be read with the `read_jhc_file` method:\n",
    "\n",
    "In the `LabD.py` script add and complete the following:\n",
    "    positions = Position()\n",
    "    positions.read_jhc_file(abs_path+...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print( positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Configured environment for Lab D\n",
    "    Opening GNSS data file:/home/jupyter-semmed/ESCI_OE_874/Data/Lab_A_GNSS.txt\n",
    "    geodetic_units: rad\n",
    "    height_units: m\n",
    "    proj_units: m\n",
    "    geoid_name: EGM08\n",
    "    ellipsoid_name: WGS84\n",
    "    height_relative_to: geoid\n",
    "    time_basis: UTC\n",
    "    proj_str: None\n",
    "    Minimum latitude       : 0.278496\n",
    "    Maximum latitude       : 0.278564\n",
    "    Minimum longitude      : 2.548137\n",
    "    Maximum longitude      : 2.548780\n",
    "    Minimum height         : 27.18m\n",
    "    Maximum height         : 82.38m\n",
    "    Start Time             : 2011-05-08 03:49:11+00:00\n",
    "    End Time               : 2011-05-08 03:49:11+00:00\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D4.0 Squaring the Positioning Data Away\n",
    "\n",
    "As we saw in lab A we want to do our calculations in a Cartesian world if we can. Thus, just like in that lab, we want to transform our coordinates to UTM coordinates. For this we will use the `Position` class `carto_project` method\n",
    "\n",
    "In the `LabD.py` script add the following:\n",
    "\n",
    "    positions.carto_project(\"UTM\", \"ortho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print( positions.proj_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Configured environment for Lab D\n",
    "    Opening GNSS data file:/home/jupyter-semmed/ESCI_OE_874/Data/Lab_A_GNSS.txt\n",
    "    [[3.92719337e+05 3.92724827e+05 3.92730791e+05 ... 3.92723976e+05\n",
    "      3.92718461e+05 3.92713022e+05]\n",
    "     [1.76481175e+06 1.76481199e+06 1.76481229e+06 ... 1.76440513e+06\n",
    "      1.76440523e+06 1.76440540e+06]\n",
    "     [2.88950000e+01 2.91460000e+01 2.89800000e+01 ... 2.88460000e+01\n",
    "      2.87760000e+01 8.23750000e+01]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D5 Get the Motion Data\n",
    "\n",
    "We will get the motion data and store them in a `Motion` object called `motions`. Just like the positioning we will do this in the same fashion as in Lab A - the data file is called `Lab_A_MRU.txt` is located in the Data folder and should be read with the `read_jhc_file` method:\n",
    "\n",
    "In the `LabD.py` script add and complete the following:\n",
    "\n",
    "    motions = Motion()\n",
    "    motions.read_jhc_file(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(motions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Configured environment for Lab D\n",
    "    Opening GNSS data file:/home/jupyter-semmed/ESCI_OE_874/Data/Lab_A_GNSS.txt\n",
    "    Opening motion data file:/home/jupyter-semmed/ESCI_OE_874/Data/Lab_A_MRU.txt\n",
    "    Start time: 2011-05-08 03:49:10.572000+00:00\n",
    "    End time:   2011-05-08 04:12:27.053000+00:00\n",
    "    angle__units: rad\n",
    "    distance_units: m\n",
    "    time_basis: UTC\n",
    "    Source File: /home/jupyter-semmed/ESCI_OE_874/Data/Lab_A_MRU.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D6 Get the Sound Speed Data\n",
    "\n",
    "We will get the sound speed data and store them in a `SSP` object called `ssp`. This time the data file is called `Lab_A_SVP.txt` and is located in the Data folder. You should read it with the `read_jhc_file` method which you may add to the SSP class.\n",
    "\n",
    "    def read_jhc_file(self, fullpath):\n",
    "        # Check to see whether data already exists in the object\n",
    "        \n",
    "        if self.obs_depths:\n",
    "            raise RuntimeError('SSP object already contains a profile')\n",
    "            \n",
    "        # Check the File's existence\n",
    "        if os.path.exists(fullpath):\n",
    "            self.metadata[\"Source File\"] = fullpath\n",
    "            print('Opening sound speed profile data file:' + fullpath)\n",
    "        else:  # Raise a meaningful error\n",
    "            raise RuntimeError('Unable to locate the input file' + fullpath)\n",
    "\n",
    "        # Open, read and close the file\n",
    "        svp_file = open(fullpath)\n",
    "        svp_content = svp_file.read()\n",
    "        svp_file.close\n",
    "\n",
    "        # Tokenize the contents\n",
    "        svp_lines = svp_content.splitlines()\n",
    "        self.obs_time = datetime.fromtimestamp(\n",
    "            float(svp_lines[1].split()[0]), timezone.utc)\n",
    "        self.log_time = datetime.fromtimestamp(\n",
    "            float(svp_lines[2].split()[0]), timezone.utc)\n",
    "        self.obs_latitude = float(svp_lines[3].split()[0])\n",
    "        self.obs_longitude = float(svp_lines[3].split()[1])\n",
    "        self.vessel_latitude = float(svp_lines[4].split()[0])\n",
    "        self.vessel_longitude = float(svp_lines[4].split()[1])\n",
    "        self.metadata[\"count\"] = int(svp_lines[5].split()[0])\n",
    "\n",
    "        count = 0  # initialize the counter for the number of rows read\n",
    "\n",
    "        for svp_line in svp_lines[16:]:\n",
    "            observations = svp_line.split()  # Tokenize the stringS\n",
    "            self.obs_sample.append(float(observations[0]))\n",
    "            self.obs_depths.append(float(observations[1]))\n",
    "            self.obs_ss.append(float(observations[2]))\n",
    "            count += 1\n",
    "\n",
    "        if self.metadata[\"count\"] != count:\n",
    "            raise RuntimeError('Nr of Samples read ('+str(count) +\n",
    "                               ') does not match metadata count (' +\n",
    "                               str(self.metadata[\"count\"])+')')\n",
    "\n",
    "        # Process the data - in the jhc data files this is already a one-way profile,\n",
    "        # this just for illustration\n",
    "        array_ss = np.zeros((count, 3))\n",
    "\n",
    "        # Sort the data samples by depth\n",
    "        sorted_ss = sorted(zip(self.obs_depths, self.obs_ss))\n",
    "        \n",
    "        layer = 0\n",
    "        for d, ss in sorted_ss:\n",
    "            array_ss[[layer], [0]] = d\n",
    "            array_ss[[layer], [1]] = ss\n",
    "            layer += 1\n",
    "\n",
    "        # Identify all the depths for which there are multiple observations\n",
    "        mask = np.full((count, 1), True)\n",
    "        mask[1:, [0]] = np.diff(array_ss[:, [0]], axis=0) != 0\n",
    "        \n",
    "        # Remove the duplicates - You really should get statistical representations here\n",
    "        # but to keep this short just remove the duplicates\n",
    "        array_ss = array_ss[mask[:, 0], ...]\n",
    "        \n",
    "        # Determine the gradients - Note the indexing: the gradient of the first layer \n",
    "        # is contained at the same index as the data for the TOP of the layer.\n",
    "        array_ss[0:-1, [2]] = np.diff(array_ss[:, [1]],\n",
    "                                          axis=0)/np.diff(array_ss[:, [0]], axis=0)\n",
    "\n",
    "        # Estimate gradient for last layer assuming that the temperature and salinity remain the same\n",
    "        # gradient solely a function of pressure (depth)\n",
    "        array_ss[-1, [2]] = 0.017\n",
    "\n",
    "        # Extend to 12000 m if necesarry - this is to get around some manufcturers requirements\n",
    "        if self.obs_depths[-1] < 12000:\n",
    "            ss = array_ss[-1:, [1]] + array_ss[-1:, [2]] \\\n",
    "             * (12000-array_ss[-1:, [0]])\n",
    "            array_ss = np.vstack((array_ss, [12000, ss, 0.017]))\n",
    "            \n",
    "        # Make sure that the last gradient is 0.017\n",
    "        array_ss[-1,2] = 0.017\n",
    "\n",
    "        # Extend to 0 m if necesarry - assume well mixed\n",
    "        if self.obs_depths[0] > 0:\n",
    "            array_ss = np.vstack(\n",
    "                ([0, array_ss[0, [1]], 0.], array_ss))\n",
    "            \n",
    "        # Step 5 Create a look-up array of twtts for each full layer\n",
    "        # Allows for great gain in efficiency (do not have to calculate for each ping)\n",
    "        self.twtt_layer = np.zeros((count, 1))\n",
    "        \n",
    "        for layer in range(0,self.metadata[\"count\"]-1):\n",
    "            if array_ss[layer, [2]] == 0:\n",
    "                self.twtt_layer[layer] = 2 * \\\n",
    "                    (array_ss[layer+1, [0]] - array_ss[layer, [0]])/ \\\n",
    "                     array_ss[layer, [1]]\n",
    "            else:\n",
    "                self.twtt_layer[layer] = 2 / array_ss[layer, [2]] * \\\n",
    "                 log(array_ss[layer+1, [1]]/array_ss[layer, [1]])\n",
    "        \n",
    "        self.proc_ss = array_ss[:,1]\n",
    "        self.proc_depth = array_ss[:,0]\n",
    "        self.g = np.diff(self.proc_ss)/np.diff(self.proc_depth)\n",
    "        self.g[self.g == 0] = .24\n",
    "        \n",
    "        # Updating the Profile\n",
    "        for i in range(1,len(self.g)):\n",
    "            self.proc_ss[i]=self.proc_ss[i-1]+(self.proc_depth[i] - self.proc_depth[i-1])*self.g[i-1]\n",
    "\n",
    "\n",
    "In the `LabD.py` script add and complete the following:\n",
    "\n",
    "    ssp = ...\n",
    "    ssp.read_jhc_file(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(ssp.proc_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Configured environment for Lab D\n",
    "    Opening GNSS data file:/home/jupyter-semmed/ESCI_OE_874/Data/Lab_A_GNSS.txt\n",
    "    Opening motion data file:/home/jupyter-semmed/ESCI_OE_874/Data/Lab_A_MRU.txt\n",
    "    Opening sound speed profile data file:/home/jupyter-semmed/ESCI_OE_874/Data/Lab_A_SVP.txt\n",
    "    [0.0e+00 2.0e+00 3.0e+00 4.0e+00 5.0e+00 6.0e+00 7.0e+00 8.0e+00 9.0e+00\n",
    "     1.0e+01 1.1e+01 1.2e+01 1.3e+01 1.4e+01 1.5e+01 1.6e+01 1.7e+01 1.8e+01\n",
    "     1.9e+01 2.0e+01 2.1e+01 2.2e+01 2.3e+01 2.4e+01 2.5e+01 2.6e+01 2.7e+01\n",
    "     2.8e+01 2.9e+01 3.0e+01 3.1e+01 3.2e+01 3.3e+01 3.4e+01 3.5e+01 3.6e+01\n",
    "     3.7e+01 3.8e+01 3.9e+01 4.0e+01 4.1e+01 4.2e+01 4.3e+01 4.4e+01 4.5e+01\n",
    "     4.6e+01 4.7e+01 4.8e+01 4.9e+01 5.0e+01 5.1e+01 5.2e+01 5.3e+01 5.4e+01\n",
    "     5.5e+01 5.6e+01 5.7e+01 5.8e+01 5.9e+01 6.0e+01 6.1e+01 6.2e+01 6.3e+01\n",
    "     6.4e+01 6.5e+01 6.6e+01 6.7e+01 6.8e+01 6.9e+01 7.0e+01 7.1e+01 7.2e+01\n",
    "     7.3e+01 7.4e+01 7.5e+01 7.6e+01 7.7e+01 7.8e+01 7.9e+01 8.0e+01 8.1e+01\n",
    "     8.2e+01 8.3e+01 8.4e+01 8.5e+01 8.6e+01 8.7e+01 8.8e+01 8.9e+01 9.0e+01\n",
    "     9.1e+01 9.2e+01 9.3e+01 9.4e+01 9.5e+01 9.6e+01 9.7e+01 9.8e+01 9.9e+01\n",
    "     1.2e+04]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D7 Get the Ping Data\n",
    "\n",
    "<img align=\"center\" width=\"80%\" style=\"padding-right:10px;\" src=\"./Images/ping.png\">\n",
    "\n",
    "A single file *data_ping_4170.txt* is supplied which, together with the orientation and offsets will allow you to do the full calculation.\n",
    "\n",
    "What information do you have on the transmit sector for the beam you chose?\n",
    "From the data telegram, there is lots of other information that is provided about each sector. The only things you need are:\n",
    "\n",
    "- the transmit steering angle and\n",
    "- the time delay between the first sector firing and the one you have chosen.\n",
    "\n",
    "Your actual time of transmission is the nominal time of the swath PLUS the extra delay while it waits for the other sectors to fire. For example, Sector 1 fired first (at the specified time). Sector 0 fires 0.4ms later and Sector 2 fire another 0.4ms after that (0.8ms w.r.t the central sector).\n",
    "\n",
    "To save you some time a `Ping` class has been created for you - you may find it in your `mycode` folder and it is already included in the dependencies.\n",
    "\n",
    "\n",
    "In the `LabD.py` script add and complete the following:\n",
    "\n",
    "    ping = Ping()\n",
    "    ping.read(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(ping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D7.0 Indexing the Ping Data\n",
    "\n",
    "As you can see from the output above the data comes with a header that describes the properties of three sectors. In the figure above you can see that this sector data is followed by a table of beam specific data. One thing to realize is that the beam number is associated to a specific beam, not the line number of the data in the table. To clarifu it may be that beams 1,2,4 and, 5 were processed successfully, but beam 3 failed. The data for beam 3 is then not included in the table. This has a result that the data for beams 1 and 2 are in records 1 and 2, but the data for beams 4 and 5 are in records 3 and 4 respectively. \n",
    "\n",
    "Thus we need a mechanism to identify the proper record, fortunately the `Ping` class comes with the `get_beam_index` method that allows us to find the record index associated to our selected beam `beam_select`\n",
    "\n",
    "In the LabD.py script add the following:\n",
    "\n",
    "    i = ping.get_beam_index(beam_select)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    391\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use analyze beam data we may now use the index that we found, which in this case is the same as the beam number itself. For example, we may interested in what the sector time delay is for the beam of interest, we may find this using: \n",
    "\n",
    "    ping.tx_t_offset_beam[i]\n",
    "    \n",
    "Which will result in a `timedelta` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ping.tx_t_offset_beam[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    0:00:00.000800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D8 Timing it Right\n",
    "\n",
    "<img align=\"center\" width=\"80%\" style=\"padding-right:10px;\" src=\"./Images/timing.bmp\">\n",
    "\n",
    "As you saw in Lab A all the integration is done based on time. We will need to know how the transducer are oriented at both the time of transmit and reception. Thus the first thing that we need to so is to determine what those points in time are. The ping time is contained in the variable `ping.tx_time`\n",
    "\n",
    "In the `LabD.py` script add the following:\n",
    "\n",
    "    t_tx = ping.tx_time+ping.tx_t_offset_beam[i]\n",
    "    t_rx = t_tx+timedelta(0,ping.twtt[i])\n",
    "\n",
    "What the code above does is to determine the time `t_tx` associated to the transmit, `ping.tx_time` is a `datetime` object and `ping.tx_t_offset_beam[i]` is a `timedelta` object, which allows us to handle the time more easily (I strongly suggest that you look at the `Ping` class implementation to gather greater understanding.\n",
    "\n",
    "The next line then adds the TWTT for the beam to the transmit time to determine the reception time `t_rx`. However, `ping.twtt[i]` is a simple float and thus needs to be transformed to a `timedelta` before we may add it to `t_tx`.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(t_tx)\n",
    "print(t_rx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2011-05-08 04:01:06.555800+00:00\n",
    "    2011-05-08 04:01:06.785567+00:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D9 Getting the Motion Data for our Epochs\n",
    "\n",
    "Now that we have the time we can orient the transducers at the time of transmit and reception. Unlike in lab A we only need to do this for a single set of transmit and receive epochs, however the same methods may be used. In our case we will add a few methods to the `Motion` class that will allow us to gather the right information\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D9.0 Getting Motion Vectors\n",
    "\n",
    "The first thing that we are interested in is the orientation of the vessel at specific epochs - we will add the method\n",
    "`get_motion` to the `Motion` class. This method will take a `datetime` argument an return the motion as a one dimensional `numpy` array. The order will be the rotation around the x-axis, y-axis, z-axis and the heave.\n",
    "\n",
    "The implementation is really the same process that we used in the `Integration` class of Lab A.\n",
    "\n",
    "\n",
    "**NOTE: IF YOU TOOK ESCI 872 YOU WILL ALREADY HAVE THIS METHOD**\n",
    "\n",
    "    def get_motion(self, time = datetime.fromtimestamp(0, timezone.utc)):\n",
    "\n",
    "        # Allocate Memory\n",
    "        attitude = np.zeros(4)\n",
    "        \n",
    "        # 7.10.2 Map the Input Times to POSIX Times\n",
    "        times = np.array([e.timestamp() for e in self.times])\n",
    "        \n",
    "        attitude[0] = np.interp(time.timestamp(), times, self.roll)\n",
    "        attitude[1] = np.interp(time.timestamp(), times, self.pitch)\n",
    "        attitude[2] = np.interp(time.timestamp(), times, self.yaw)\n",
    "        attitude[3] = np.interp(time.timestamp(), times, self.heave)\n",
    "\n",
    "\n",
    "In the LabD.py script add and complete the following:\n",
    "\n",
    "    att_tx = motions.get_motion(t_tx)\n",
    "    att_rx = motions.get_motion(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(att_tx)\n",
    "print(att_rx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    [ -0.0188  0.0365  3.7564  0.0378]\n",
    "    [ -0.0277  0.0356  3.7634  0.1400]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D9.1 Getting Orientation Matrices\n",
    "\n",
    "For many of our purposes it makes more sense to use a rotation matrix to represent our orientation and leave out the heave, which is a translational motion. For this you should add the following method to your `Motion` class\n",
    "\n",
    "    def get_rotation_matrix(self, time = datetime.fromtimestamp(0, timezone.utc)):\n",
    "        # 7.11.1 Determining the Attitude\n",
    "        att = self.get_motion(time)\n",
    "\n",
    "        Rx = np.array([[1, 0,            0          ],\n",
    "                       [0, cos(att[0]), -sin(att[0])],\n",
    "                       [0, sin(att[0]),  cos(att[0])]])\n",
    "\n",
    "        Ry = np.array([[ cos(att[1]),  0, sin(att[1])],\n",
    "                       [ 0          ,  1, 0          ],\n",
    "                       [-sin(att[1]),  0, cos(att[1])]])\n",
    "\n",
    "        Rz = np.array([[cos(att[2]), -sin(att[2]), 0],\n",
    "                       [sin(att[2]),  cos(att[2]), 0],\n",
    "                       [0          ,  0          , 1]])\n",
    "                       \n",
    "        return Rz@Ry@Rx\n",
    "\n",
    "\n",
    "In the LabD.py script add and complete the following:\n",
    "\n",
    "    R_tx = motions.get_rot_matrix(t_tx)\n",
    "    R_rx = motions....()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(R_tx)\n",
    "print(R_rx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    [[ -0.8163  0.5773  -0.0190]\n",
    "     [ -0.5764  -0.8163  -0.0364]\n",
    "     [ -0.0365  -0.0188  0.9992]]\n",
    "    [[ -0.8123  0.5831  -0.0128]\n",
    "     [ -0.5821  -0.8120  -0.0432]\n",
    "     [ -0.0356  -0.0276  0.9990]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D10 Finding out Where We Are \n",
    "\n",
    "Next up is the determination of the vessel location at our epochs of interest - we will add the method\n",
    "`get_position` to the `Position` class. This method will take a `datetime` argument an return the position as a one dimensional `numpy` array. The order of the elements should be the same as that in the `Position.proj_pos` array.\n",
    "\n",
    "    def get_position(self, time = datetime.fromtimestamp(0, timezone.utc)):\n",
    "        pos = np.zeros(3)\n",
    "        times = np.array([e.timestamp() for e in self.times])\n",
    "        pos[0] = np.interp(time.timestamp(), times, self.proj_pos[0])\n",
    "        pos[1] = ...\n",
    "        pos[2] = ...\n",
    "        \n",
    "        return pos\n",
    "        \n",
    "In the LabD.py script add and complete the following:\n",
    "\n",
    "    geo_tx_ant = positions.get_position(t_tx)\n",
    "    geo_rx_ant = positions.get_position(t_rx)\n",
    "    \n",
    "This gives the georeferenced position of the GNSS antenna at the transmit epoch `geo_tx_ant` and receive epoch `geo_rx_ant`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(geo_tx_ant)\n",
    "print(geo_rx_ant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    [3.96628073e+05 1.76453295e+06 2.85175464e+01]\n",
    "    [3.96627798e+05 1.76453196e+06 2.84045010e+01]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D11 Georeferencing the Lever Arms\n",
    "\n",
    "Just like in Lab A we will need to determine our lever arms in georeferenced space. We will need to geo-reference the antenna lever arm to be able to position the reference point (rp) at both the transmit and receive epochs. Similarly we will need the georeferenced transducer lever arms to be able to locate the transducer using the rp in geo-referenced space. We may use the `Motion.geo_reference_la` method for this purpose.\n",
    "\n",
    "First we will calculate the georeferenced GNSS lever arm `geo_tx_ant` for epoch `t_tx` and then `geo_tx_ant` for epoch `t_rx`\n",
    "\n",
    "In the LabD.py script add and complete the following:\n",
    "\n",
    "    geo_pos_la_tx = motions.geo_reference_la(t_tx, vessel.lever_arm_pos)\n",
    "    geo_pos_la_rx = ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(geo_pos_la_tx)\n",
    "print(geo_pos_la_rx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    [[ 5.1770]\n",
    "     [ 4.4920]\n",
    "     [ -29.7635]]\n",
    "    [[ 4.9700]\n",
    "     [ 4.7300]\n",
    "     [ -29.7619]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D12 Calculating the Reference Position RP\n",
    "\n",
    "Again like lab A we need to determine the location of our reference point `geo_pos_rp_tx` at `t_tx` and `geo_pos_rp_rx` at `t_rx`. We will store these locations in 3x1 column vectors. Just like in Lab A you have to be careful to be careful about axis alignment:\n",
    "\n",
    "In the LabD.py script add and complete the following:\n",
    "\n",
    "    geo_pos_rp_tx = np.zeros((3,1))\n",
    "    geo_pos_rp_rx = ...\n",
    "\n",
    "    geo_pos_rp_tx[0] =  geo_tx_ant[0] - geo_pos_la_tx[1]\n",
    "    geo_pos_rp_tx[1] =  geo_tx_ant[1] - geo_pos_la_tx[0]\n",
    "    geo_pos_rp_tx[2] = -geo_tx_ant[2] - geo_pos_la_tx[2]\n",
    "\n",
    "    geo_pos_rp_rx[0] =  ...\n",
    "    geo_pos_rp_rx[1] =  ...\n",
    "    geo_pos_rp_rx[2] =  ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(geo_pos_rp_tx)\n",
    "print(geo_pos_rp_rx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    [[ 396623.5810]\n",
    "     [ 1764527.7769]\n",
    "     [ 1.2460]]\n",
    "    [[ 396623.0679]\n",
    "     [ 1764526.9894]\n",
    "     [ 1.3574]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## D13 The Separation of Shot and Receive\n",
    "\n",
    "<img align=\"center\" width=\"80%\" style=\"padding-right:10px;\" src=\"./Images/separation_shot_receive.jpg\">\n",
    "\n",
    "As there is a finite time between transmission and reception, both the position and the orientation of the array will change in that interval. That interval can typically range from ~1/10 of second (<75m ranges) to 10’s of seconds for deep water systems.\n",
    "\n",
    "If a single location value is to be used, the average of the transmitter position at transmit and receiver position at the average received TWTT can reasonably be used, as we did in Lab A. Strictly though, over the reception cycle, the receiver does propagate forward. But at typical vessel speeds (~4m/s) the distance traveled, compared to the one way sound speed (750 m/s) is a very small fraction (0.5%) which is smaller than the beam footprint. For example, the projected beam width of a 0.5$^{\\circ}$ beam is 0.87% of Z (strictly slant range). Both these numbers are small compared to IHO Special Order horizontal accuracy requirements of 2m in 40m of water which corresponds to only 5% of Z.\n",
    "\n",
    "**Note** that this excludes the physical separation of the transmitter and receiver acoustic centers (normally at least ½ the physical array length). If bottom detection is attempted in the acoustic near field, that separation may be significantly larger than the forward propagation of the sonar over the ping cycle.\n",
    "\n",
    "Unlike lab A we cannot take a simple average, the beam steering is applied at the specific transmit and receive times, so we will create a virtual transducer with the transmit element located and oriented at `t_tx` and the receive element located and oriented at `t_rx`. Thus we need to have a vector that describes the distance traveled between those two epochs. We will use the vector `geo_pos_diff` for that purpose.\n",
    "\n",
    "<img align=\"center\" width=\"80%\" style=\"padding-right:10px;\" src=\"./Images/geo_pos_diff.PNG\">\n",
    "\n",
    "In the LabD.py script add the following:\n",
    "\n",
    "    geo_pos_diff = geo_pos_rp_rx - geo_pos_rp_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'geo_pos_diff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/ESCI_OE_874_Clean/LabD.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'run'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-i LabD.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeo_pos_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'geo_pos_diff' is not defined"
     ]
    }
   ],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(geo_pos_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Configured environment for Lab D\n",
    "    Opening GNSS data file:/home/jupyter-semmed/ESCI_OE_874/Data/Lab_A_GNSS.txt\n",
    "    Opening motion data file:/home/jupyter-semmed/ESCI_OE_874/Data/Lab_A_MRU.txt\n",
    "    Opening sound speed profile data file:/home/jupyter-semmed/ESCI_OE_874/Data/Lab_A_SVP.txt\n",
    "    Data/data_ping_4170.txt\n",
    "    Opening sound speed profile data file:Data/data_ping_4170.txt\n",
    "    [[ -0.7875]\n",
    "     [ -0.5131]\n",
    "     [ 0.1114]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## D14 Course Over Ground\n",
    "\n",
    "<img align=\"center\" width=\"80%\" style=\"padding-right:10px;\" src=\"./Images/cog.PNG\">\n",
    "\n",
    "Now that we have this vector we know what the course over ground (cog) between the transmit and receive epoch was.\n",
    "\n",
    "Note that after this it is more convenient to change the order in the `geo_pos_diff` vector\n",
    "\n",
    "In the LabD.py script add the following:\n",
    "\n",
    "    cog = arctan2(geo_pos_diff[0],geo_pos_diff[1])\n",
    "    \n",
    "    temp = geo_pos_diff.copy()\n",
    "    geo_pos_diff[0] = temp[1]\n",
    "    geo_pos_diff[1] = temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cog' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/ESCI_OE_874_Clean/LabD.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'run'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-i LabD.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeo_pos_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cog' is not defined"
     ]
    }
   ],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(cog)\n",
    "print(geo_pos_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    [ -2.5641]\n",
    "    [[ -0.5131]\n",
    "     [ -0.7875]\n",
    "     [ 0.1114]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## D15 Drift Angle\n",
    "\n",
    "<img align=\"center\" width=\"80%\" style=\"padding-right:10px;\" src=\"./Images/da.PNG\">\n",
    "\n",
    "The difference between the cog and the heading is known as the drift angle\n",
    "\n",
    "Pet peeve alert (ignore if you like): often the drift angle is incorrectly referred to as the crab angle. The crab angle is actually a course correction applied by the navigator to achieve the desired course over ground! the Crab angle should therefore be in the opposite direction of the drift angle, but may be of a different magnitude.\n",
    "\n",
    "remember that the heading at transmit is given by `att_tx[2]`\n",
    "\n",
    "In the LabD.py script add and complete the following:\n",
    "\n",
    "    da=(...-...[2])[0]\n",
    "    while da < -pi:\n",
    "         da = da + 2 * pi\n",
    "    while da > pi:\n",
    "        d..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(da)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -0.037315440834639446"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## D16 Heading Change\n",
    "\n",
    "<img align=\"center\" width=\"80%\" style=\"padding-right:10px;\" src=\"./Images/dh_1.PNG\">\n",
    "\n",
    "The next thing we need is to determine the heading change between the epochs, as this will contribute to the difference in alignment between the transmit transducer at `t_tx` and the receive transducer at `t_rx`.\n",
    "\n",
    "<img align=\"center\" width=\"80%\" style=\"padding-right:10px;\" src=\"./Images/dh_2.PNG\">\n",
    "\n",
    "In the LabD.py script add and complete the following:\n",
    "\n",
    "    d_h=att_rx[2]-att_tx[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(d_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    0.006934786545932159\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## D17 Equivalent Modeled Virtual Array\n",
    "\n",
    "<img align=\"center\" width=\"80%\" style=\"padding-right:10px;\" src=\"./Images/eq_model.jpg\">\n",
    "\n",
    "To calculate a single beam vector for the outgoing and incoming ray path, an equivalent array geometry needs to be defined in which the acoustic centers of the transmit and receive transducers are co-located.\n",
    "\n",
    "The figure above illustrates the modeled beam vector solution. A virtual array location, half way in X,Y and Z from the acoustic center at transmit and receive is calculated. The alignment of the transmit transducer is defined by the attitude at transmit, the alignment of the receive transducer is determined by the attitude at reception. The arrays are no longer mutually orthogonal (even if the physically constructed arrays actually are)as time has elapsed.\n",
    "\n",
    "We will create a new reference system based on the location and orientation of the transmit transducer at the transmit epoch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Creating A new Reference System\n",
    "\n",
    "With the results from D14-D17 we can calculate the orientation of the long axis of the transmitter and receiver at the transmit and receive epochs. Recall from class that the steered beams are oriented around those long axes.\n",
    "\n",
    "Ideally the transducers are aligned to the X and Y-axes and are orthogonal to each other at the time of transmission and reception. As we have seen this is not the case, but we have all the information needed to construct a virtual array. We know the orientation of the transmit array at transmit epoch `t_tx` and receive epoch `t_rx`. We also know how the vessel moved by in the intervening epoch `geo_pos_diff`. If we assume that the transmit transducer is aligned to the x-axis  then we need to determine where the receive transducer is relative to the transmit transducer. \n",
    "\n",
    "We will create a new reference system that is:\n",
    "\n",
    "- Right handed Cartesian\n",
    "- Uses SI units for scale\n",
    "- Has the origin defined by rp location at the transmit \n",
    "- The ideal transducer long axis is aligned to the VRF x-axis \n",
    "- Has the 1-axis in the direction of the ideal long axis of the transmit transducer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## D17.0 Aligning `geo_pos_diff` to the 1-Axis\n",
    "\n",
    "<img align=\"center\" width=\"80%\" style=\"padding-right:10px;\" src=\"./Images/ref_pos_diff.PNG\">\n",
    "\n",
    "We want to create a new 1-axis that is aligned to the X-axis of the vessel reference frame at the time of transmit i.e., the new 1-axis will be in the direction of the heading at the time of transmit. This means that the lever arms at the time of transmit are already aligned to the direction of the new 1-axis. The vector `geo_pos_diff` connecting the RP at transmit and receive will need to be rotated. In the figure you will see that the resulting vector will be almost coincident with the 1-axis, differing by just the drift angle `da`. We will call the resulting vector `ref_pos_diff`.\n",
    "\n",
    "In the LabD.py script add the following:\n",
    "\n",
    "    ref_pos_diff = Rz(-att_tx[2])@geo_pos_diff\n",
    "    \n",
    "Note the value of the 2-axis element - it will typically be close to zero, unless a significant drift angle is encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(ref_pos_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    [[ 0.9393]\n",
    "     [ -0.0351]\n",
    "     [ 0.1114]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## D17.1 New Transmit Transducer Lever Arm\n",
    "\n",
    "<img align=\"center\" width=\"80%\" style=\"padding-right:10px;\" src=\"./Images/ref_pos_diff.PNG\">\n",
    "\n",
    "The lever arm to the transmit transducer is already centered on the new origin (the RP at transmit) and aligned to the new 1-axis. Thus the only thing that we need to do to get the coordinates of the transmit transducer is to compensate for motion by rotating the lever arm for roll and pitch.\n",
    "\n",
    "In the LabD.py script add and complete the following:\n",
    "\n",
    "    # D17.1 New Transmit Transducer Lever Arm\n",
    "    new_la_tx = Ry(...)@Rx(...)@vessel.lever_arm_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(new_la_tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    [[16.40170235]\n",
    "     [-1.67178928]\n",
    "     [ 3.5863464 ]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## D17.2 New Receive Transducer Lever Arm\n",
    "\n",
    "The lever arm to the receive transducer is not centered on the new origin (the RP at transmit) nor aligned to the new 1-axis. \n",
    "\n",
    "<img align=\"center\" width=\"80%\" style=\"padding-right:10px;\" src=\"./Images/new_la_rx.PNG\">\n",
    "\n",
    "From the figure above we can see that the RP at reception is offset by the translation vector `ref_pos_diff`. We can also see that the vessel reference frame at the time of reception needs to be rotated by the difference in heading `d_h` between the transmit and receive epochs.\n",
    "\n",
    "Finally the receive transducer lever arm will need to be rotated to compensate for roll and pitch at the reception epoch which is contained in the array `att_rx`.\n",
    "\n",
    "Note that the order matters, we will rotate in the order roll, pitch, heading difference, i.e., $\\text{R}_z\\cdot\\text{R}_y\\cdot\\text{R}_x$\n",
    "\n",
    "In the LabD.py script add and complete the following:\n",
    "\n",
    "    # D17.2 New Receive Transducer Lever Arm\n",
    "    new_la_rx = Rz(...)@Ry(...)@Rx(...)@vessel.lever_arm_rec+ref_pos_diff\n",
    "    \n",
    "This positions the transducer with respect to the vessel reference frame as it was at the transmit epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(new_la_rx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    [[15.91315915]\n",
    "     [-1.82514732]\n",
    "     [ 3.8045833 ]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## D17.3 Virtual Transducer location: Why colocation?\n",
    "\n",
    "We are concerned with establishing the point on the seafloor at which the conical maximum response axes of the transmitter and receiver intersect. In reality, the two cones will be distorted by refraction. If the two acoustic centers are not at the same location, then the refracted ray paths from each center to the strike point will not be identical. However, if they are concentric, they will share the same distortion. Under this special circumstance, we can ignore the refraction and just deal with a single vector which represents the initial ray vector as it leave/returns to the Mills cross - thus using a virtual transducer will lead to much simpler math, even though a small amount off distortion is unavoidable.\n",
    "\n",
    "<img align=\"center\" width=\"80%\" style=\"padding-right:10px;\" src=\"./Images/colocation.PNG\">\n",
    "\n",
    "We will create a virtual transducer at the halfway point between the acoustic center of the transmit transducer at transmit, given by the lever arm `new_la_tx`, and the acoustic center of the receive transducer at reception, given by the lever arm `new_la_rx`\n",
    "\n",
    "In the LabD.py script add and complete the following:\n",
    "\n",
    "    # D17.3 Virtual Transducer location; Why colocation?\n",
    "    new_virtual_trans = (...+...)/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_virtual_trans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/ESCI_OE_874_Clean/LabD.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'run'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-i LabD.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_virtual_trans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'new_virtual_trans' is not defined"
     ]
    }
   ],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(new_virtual_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    [[ 16.1574]\n",
    "     [ -1.7485]\n",
    "     [ 3.6955]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## D17.4 Virtual Transducer location: Vertical Placement\n",
    "\n",
    "We now know the positions of the transmit and receive transducer in the new reference frame, which coincides with the vessel reference frame as it was at the time of transmit. We however want to position the virtual transducer with respect to the water line, so that we may use its vertical position component as the starting point for our ray tracing. Since we are ray tracing based on a single acoustic center in the virtual array we want to offset its z coordinate by the distance of the rp to the waterline at transmit and receive time. This is the combination of the static draft and average heave (remember that the effects of roll and pitch are already accounted for). We will represent this location by the 3x1 column vector `virtual_trans`.\n",
    "\n",
    "Remember that the heave is stored in `att_tx[2]` and `att_rx[2]` respectively and that the rp tp waterline offset is given by `vessel.wl`. Make sure to get the signs right!\n",
    "\n",
    "In the LabD.py script add and complete the following:\n",
    "\n",
    "    # D17.4 Virtual Transducer location: Vertical Placement\n",
    "    virtual_trans = new_virtual_trans.copy()\n",
    "    virtual_trans[2] += (att_tx[3] + att_rx[3]) / 2 - vessel.wl\n",
    "    \n",
    "After this we will use $\\text{tx}_v$ to indicate the virtual transducer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(virtual_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    [[ 16.1574]\n",
    "     [ -1.7485]\n",
    "     [ 6.3744]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## D18 The Intersection of Non-Orthogonal Cones \n",
    "\n",
    "<img align=\"center\" width=\"80%\" style=\"padding-right:10px;\" src=\"./Images/non_ortho_cones.jpg\">\n",
    "\n",
    "The relative alignment of the transmitter and receiver is precisely known and is usually as close to orthogonal as possible. This is known as it is either machined in the factory for a small sonar or precisely as-placed surveyed after installation on the hull. While their relative alignment is known at a single time the geometry of the Mills Cross used to estimate the formed beam vector cannot assume that same relative misalignment. As we have seen in the previous steps at the time of the receive, the receiver will no longer share the same orientation as the transmitter at time of transmit.\n",
    "\n",
    "As a result, the beam vector has to modeled by calculating the intersection of non-orthogonal cones\n",
    "\n",
    "To calculate the resultant beam vector, one must know all of:\n",
    "    - the orientation of the transmitter long axis at transmit time `t_tx`\n",
    "    - The orientation of the receiver long axis at receive time `t_rc` \n",
    "    - the transit steering angle relative to the long axis of transmit array\n",
    "    - The receiver steering angle (at the time of receive) relative to the long axis of the receiver array\n",
    "\n",
    "Each of the steering angles, relative to the long axis of the transmitter and receiver, depend on an assumption of the sound speed at the array. During acquisition, a specific surface sound speed value is used on which the element-specific time delays are based. Thus if there is any reason to reapply a different surface sound speed, all the array-relative steering angles have to be adjusted.\n",
    "\n",
    "In this section we will be following the cone to cone intersection process as outlined in the document [Hughes Clarke \"ccom874_C18_cone_intersection_2016.pdf\"](./References/ccom874_C18_cone_intersection_2016.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## D18.0 Ideal Transducer \n",
    "\n",
    "Remember that in step D2 we created the unit vectors `tx_ideal` and `rx_ideal`; these are what we will be using in this segment.\n",
    "\n",
    "Two cones from mutually orthogonal arrays, only intersect if the sum of the two steering angles is less than 90$^{\\circ}$. For the case of a multibeam, the transmitter steering is generally less than 5 degrees (up to 15 though if heavy yaw stabilization is utilized). Thus receiver steering angles of up to 85 (75 for a heavy yaw stabilization condition) are allowable.\n",
    "\n",
    "Remember that the angle between vectors is given by:\n",
    "\n",
    "$$\\cos\\alpha = \\frac{\\overrightarrow{a}\\cdot\\overrightarrow{b}}{\\|a\\|\\|b\\|}$$\n",
    "\n",
    "Sign Conventions:\n",
    "\n",
    "Note the conventions used in the following calculations. The unit vector for the transmitter `tx_ideal` is 1,0,0 i.e., it is a vector pointing in the SRF forward or x-axis direction. The unit vector for the the receiver `rx_ideal` is 0,1,0 i.e., a vector pointing in the starboard or positive y-direction. Positive steering is defined as toward the principal vector orientation. Thus +ve forward for transmission, and positive starboard for reception. When unpacking third party sonar telegrams, the sign of the steering must be clarified as it is not a standard. **This differs from the right hand rule for the axis!**\n",
    "\n",
    "Add the statement `from numpy.linalg import norm` to the imports in your file `LabD.py` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(\"\\n\\ntx_ideal:\")\n",
    "print(tx_ideal)\n",
    "print(\"\\nrx_ideal:\")\n",
    "print(rx_ideal)\n",
    "\n",
    "# Thus cos alpha\n",
    "\n",
    "cos_a = float(tx_ideal.T@rx_ideal)/(norm(tx_ideal)*norm(rx_ideal))\n",
    "print(\"\\nIdeal angle: %.6f\"%(arccos(cos_a)*180/pi))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    tx_ideal:\n",
    "    [[ 1.0000]\n",
    "     [ 0.0000]\n",
    "     [ 0.0000]]\n",
    "\n",
    "    rx_ideal:\n",
    "    [[ 0.0000]\n",
    "     [ 1.0000]\n",
    "     [ 0.0000]]\n",
    "\n",
    "    Ideal angle: 90.000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## D18.1 Align Transducer Arrays to the Vessel Reference Frame\n",
    " \n",
    "<img align=\"center\" width=\"80%\" style=\"padding-right:10px;\" src=\"./Images/align_tx.jpg\">\n",
    "\n",
    "Starting with an ideal transmit vector `tx_ideal` of (1,0,0).\n",
    "Establishing the as-installed vector accounting for the transmit transducer mounting angles relative to the SRF. **Note that the notation order of angles is reversed in the image above** i.e. the heading is listed first, whereas it is the rotation around the z- or 3- axis. In our code we will keep the order of the angles the same as the order of the axes.\n",
    "\n",
    "$$\\overrightarrow{\\text{tx}}_{mount} = \\text{R}_z\\left(\\beta_{tx}\\right)\\cdot\\text{R}_y\\left(\\phi_{tx}\\right)\\cdot\\text{R}_x\\left(\\theta_{tx}\\right)\\cdot\\overrightarrow{\\text{tx}}_{ideal}$$\n",
    "\n",
    "$$\\overrightarrow{\\text{rx}}_{mount} = \\text{R}_z\\left(\\beta_{rx}\\right)\\cdot\\text{R}_y\\left(\\phi_{rx}\\right)\\cdot\\text{R}_x\\left(\\theta_{rx}\\right)\\cdot\\overrightarrow{\\text{rx}}_{ideal}$$<br>\n",
    "\n",
    "where:\n",
    "\n",
    "$\\theta_{tx}$: transmit transducer roll mount angle <br>\n",
    "$\\phi_{tx}$: transmit transducer roll mount angle <br>\n",
    "$\\beta_{tx}$: transmit transducer roll mount angle <br><br>\n",
    "$\\theta_{tx}$: receive transducer roll mount angle <br>\n",
    "$\\phi_{tx}$: receive transducer roll mount angle <br>\n",
    "$\\beta_{tx}$: receive transducer roll mount angle <br>\n",
    "\n",
    "In our code we will use the variable `tx_mount` to represent $\\text{tx}_{mount}$ and `rx_mount` to represent $\\text{rx}_{mount}$. Remember from D2.0 that the mount angles are given by the arrays `ma_tx` and `ma_rx` respectively \n",
    "\n",
    "In the LabD.py script add and complete the following:\n",
    "\n",
    "    # D18.1 Align Transducer Arrays to the Vessel Reference Frame\n",
    "    tx_mount = Rz(ma_tx[2])@Ry(...[1])@Rx(...)@tx_ideal\n",
    "    rx_mount = ...(ma_rx[2])@...(...)@...@rx_ideal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(\"\\n\\ntx_mount:\")\n",
    "print(tx_mount)\n",
    "print(\"\\nrx_mount:\")\n",
    "print(rx_mount)\n",
    "\n",
    "# Thus cos alpha\n",
    "\n",
    "cos_a = float(tx_mount.T@rx_mount)/(norm(tx_mount)*norm(rx_mount))\n",
    "print(\"\\nMount angle: %.6f\"%(arccos(cos_a)*180/pi))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    tx_mount:\n",
    "    [[ 0.9998]\n",
    "     [ -0.0008]\n",
    "     [ -0.0179]]\n",
    "\n",
    "    rx_mount:\n",
    "    [[ -0.0011]\n",
    "     [ 1.0000]\n",
    "     [ 0.0018]]\n",
    "\n",
    "    Mount angle: 90.108212"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## D.18.2 Correct for Orientation at Transmit\n",
    " \n",
    "<img align=\"center\" width=\"80%\" style=\"padding-right:10px;\" src=\"./Images/tx_with_motion.jpg\">\n",
    "\n",
    "Starting with the transmit mount alignment vector `tx_mount` create the transmit vector $\\overrightarrow {tx}_{tx}$ for the transmit epoch relative to geo-referenced directions i.e., taking roll, pitch and heading of the SRF into account. We will store the result in the `numpy` array `tx`\n",
    "\n",
    "$$\\overrightarrow{\\text{tx}}\\left(t_{tx}\\right) = \\text{R}_z\\left(\\beta\\left(t_{tx}\\right)\\right)\\cdot\\text{R}_y\\left(\\phi\\left(t_{tx}\\right)\\right)\\cdot\\text{R}_x\\left(\\theta\\left(t_{tx}\\right)\\right)\\cdot\\overrightarrow{\\text{tx}}_{mount}\\Rightarrow$$\n",
    "\n",
    "$$\\overrightarrow{\\text{tx}}\\left(t_{tx}\\right) = \\text{R}_z\\left(0\\right)\\cdot\\text{R}_y\\left(\\phi\\left(t_{tx}\\right)\\right)\\cdot\\text{R}_x\\left(\\theta\\left(t_{tx}\\right)\\right)\\cdot\\overrightarrow{\\text{tx}}_{mount}$$\n",
    "\n",
    "where:\n",
    "\n",
    "$\\theta\\left(t_{tx}\\right)$: roll angle at epoch $t_{tx}$ <br>\n",
    "$\\phi\\left(t_{tx}\\right)$: pitch angle at epoch $t_{tx}$ <br>\n",
    "$\\beta\\left(t_{tx}\\right)$: yaw angle in the new reference frame at epoch $t_{tx}$ <br>\n",
    "\n",
    "Remember that we aligned the new reference frame to the heading i.e., we should use the transmit epoch observed roll and pitch stored in `att_tx`, but zero for the yaw angle.\n",
    "\n",
    "In the LabD.py script add the following:\n",
    "\n",
    "    # D.18.2 Correct for Orientation at Transmit\n",
    "    tx=Rz(0)@Ry(att_tx[1])@Rx(att_tx[0])@tx_mount\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(\"\\n\\ntx:\")\n",
    "print(tx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    tx:\n",
    "    [[ 0.9985]\n",
    "     [ -0.0011]\n",
    "     [ -0.0543]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## D.18.3 Correct for Orientation at Receive\n",
    " \n",
    "<img align=\"center\" width=\"80%\" style=\"padding-right:10px;\" src=\"./Images/rx_with_motion.jpg\">\n",
    "\n",
    "Starting with the receive mount alignment vector `rx_mount` create the receive vector $\\overrightarrow {rx}_{rx}$ for the transmit epoch relative to geo-referenced directions i.e., taking roll, pitch and heading of the SRF into account. We will store the result in the `numpy` array `rx`\n",
    "\n",
    "$$\\overrightarrow{\\text{rx}}\\left(t_{rx}\\right) = \\text{R}_z\\left(\\beta\\left(t_{rx}\\right)\\right)\\cdot\\text{R}_y\\left(\\phi\\left(t_{rx}\\right)\\right)\\cdot\\text{R}_x\\left(\\theta\\left(t_{rx}\\right)\\right)\\cdot\\overrightarrow{\\text{rx}}_{mount}\\Rightarrow$$\n",
    "\n",
    "$$\\overrightarrow{\\text{rx}}\\left(t_{rx}\\right) = \\text{R}_z\\left(\\Delta\\beta\\right)\\cdot\\text{R}_y\\left(\\phi\\left(t_{rx}\\right)\\right)\\cdot\\text{R}_x\\left(\\theta\\left(t_{rx}\\right)\\right)\\cdot\\overrightarrow{\\text{rx}}_{mount}\\Rightarrow$$\n",
    "\n",
    "where:\n",
    "\n",
    "$\\theta\\left(t_{rx}\\right)$: roll angle at epoch $t_{rx}$ <br>\n",
    "$\\phi\\left(t_{rx}\\right)$: pitch angle at epoch $t_{rx}$ <br>\n",
    "$\\beta\\left(t_{rx}\\right)$: yaw angle in the new reference frame at epoch $t_{rx}$ <br>\n",
    "$\\Delta\\beta\\left(t_{rx}\\right)$: heading difference between epochs  $t_{tx}$ and  $t_{rx}$ $ <br>\n",
    "\n",
    "Remember that we aligned the new reference frame to the heading at reception i.e., we should use the transmit epoch observed roll and pitch stored in `att_rx`, but `d_h` for the yaw angle.\n",
    "\n",
    "In the LabD.py script add and complete the following:\n",
    "\n",
    "    # D.18.3 Correct for Orientation at Transmit\n",
    "    rx=Rz(...)@Ry(...)@Rx(...)@rx_mount\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(\"\\n\\nrx:\")\n",
    "print(rx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    rx:\n",
    "    [[ -0.0090]\n",
    "     [ 0.9996]\n",
    "     [ -0.0258]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D18.4 Calculate the Non-Orthogonality angle `non_ortho`\n",
    "\n",
    "<img align=\"center\" width=\"80%\" style=\"padding-right:10px;\" src=\"./Images/no.jpg\">\n",
    "\n",
    "$$\\|\\overrightarrow{\\text{tx}}\\| = 1, \\|\\overrightarrow{\\text{rx}}\\| = 1$$\n",
    "$$\\cos\\alpha = \\frac{\\overrightarrow{a}\\cdot\\overrightarrow{b}}{\\|a\\|\\|b\\|}\\Rightarrow$$<br><br>\n",
    "$$\\alpha = \\arccos\\left(\\overrightarrow{\\text{tx}}\\cdot\\overrightarrow{\\text{rx}}\\right)$$\n",
    "\n",
    "\n",
    "We expect the angle to be orthogonal i.e. $\\pi/2$ so the non-orthogonality is the difference with $\\pi/2$.\n",
    "\n",
    "$$no = \\arccos\\left(\\overrightarrow{\\text{tx}}\\cdot\\overrightarrow{\\text{rx}}\\right)-\\pi/2\\Rightarrow$$\n",
    "\n",
    "\n",
    "$$no = -\\arcsin\\left(\\overrightarrow{\\text{tx}}\\cdot\\overrightarrow{\\text{rx}}\\right)$$\n",
    "\n",
    "Note that for the arcsin you need to supply a scalar i.e., if you determine the inner product as `tx.T@rx` you will need to cast it to `float`.\n",
    "\n",
    "In the LabD.py script add and complete the following:\n",
    "\n",
    "    # D18.4 Calculate the Non-Orthogonality angle non_ortho\n",
    "    non_ortho=-arcsin(float(tx.T@rx))\n",
    "    \n",
    "also make sure to import the `arcsin` function from `numpy`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(\"\\n\\nnon_ortho:\")\n",
    "print(non_ortho)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    non_ortho:\n",
    "    0.008630371782925028"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D18.5 Create a New Orthonormal Basis XYZ'\n",
    "\n",
    "Rather than following steps 5-9 in the document [Hughes Clarke \"ccom874_C18_cone_intersection_2016.pdf\"](./References/ccom874_C18_cone_intersection_2016.pdf) we will use the more elegant alternative provided in step 5'. Once you get used to **linear algebra** this is a more intuitive and certainly more efficient alternative. \n",
    "\n",
    "<img align=\"center\" width=\"80%\" style=\"padding-right:10px;\" src=\"./Images/no.jpg\">\n",
    "\n",
    "However, to use this solution we will need to create a new Cartesian reference frame $XYZ'$ that has its $XY'$ plane spanning the vectors $\\overrightarrow{\\text{tx}}$ and $\\overrightarrow{\\text{rx}}$ - in the figure above this is the blue plane. Cartesian systems are orthonormal and the cross product of two vectors creates a vector orthogonal to them, thus we may use the normalized cross product of $\\overrightarrow{\\text{tx}}$ and $\\overrightarrow{\\text{rx}}$ to create a new $Z'$ that is orthogonal to the $XY'$ plane and held by the variable `zp`.\n",
    "\n",
    "$$\\overrightarrow Z' = \\frac{\\overrightarrow{\\text{tx}}\\times\\overrightarrow{\\text{rx}}}{\\|\\overrightarrow{\\text{tx}}\\times\\overrightarrow{\\text{rx}}\\|}$$\n",
    "\n",
    "We have not yet created an orthonormal system. We still need to define the X' axis as variable `xp`, which we may do by simply aligning it to the $\\overrightarrow{\\text{tx}}$ vector, which is already a unit vector.\n",
    "\n",
    "$$\\overrightarrow{X'} = \\overrightarrow{\\text{tx}}$$\n",
    "\n",
    "Finally, we may now define the $Y'$ axes held by the variable `yp`, as it is orthogonal to both $X'$ and $'Y'$ it is simply the normalized cross product:\n",
    "\n",
    "$$\\overrightarrow{Y'} = \\frac{\\overrightarrow{X'}\\times \\overrightarrow{Z'}}{\\|\\overrightarrow{X'}\\times \\overrightarrow{Z'}\\|}$$\n",
    "\n",
    "$XYZ'$ is now comprised of unit vectors that describe how the transducer array is oriented with respect to the real world we may combine them together in a rotation matrix that establishes the transformation $\\text{T}_p$ from the transducer to the real world i.e., if we have a transducer array relative vector $\\overrightarrow {bv}$ then the georeferenced version of that vector is $\\text{T}_p\\overrightarrow {bv}$\n",
    "\n",
    "$$T_p=\\{X'|Y'|Z'\\}$$\n",
    "\n",
    "In the LabD.py script add the following:\n",
    "\n",
    "    # D18.5 Create a New Orthonormal Basis XYZ'\n",
    "    xp=tx.copy()\n",
    "    zp=np.cross(tx.T,rx.T).T\n",
    "    zp/=norm(zp)\n",
    "    yp=np.cross(zp.T,xp.T).T\n",
    "    yp/=norm(yp)\n",
    "    Tp = np.hstack((xp, yp, zp)) \n",
    "    \n",
    "Note the use of the `numpy` hstack function, which allows us to horizontally augment (combine) the three column vectors to create the Rotation matrix `Tp` defining the coordinate system $XYZ'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(\"\\n\\nTp:\")\n",
    "print(Tp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## D18.6 Formula for Intersection of Orthogonal Arrays\n",
    " \n",
    "<img align=\"center\" width=\"80%\" style=\"padding-right:10px;\" src=\"./Images/ortho_concentric.jpg\">\n",
    "\n",
    "Let use a unit vector $bv_p$ to represent the beam leaving the transducer array. For now let's consider the ideal case i.e., the arrays are orthogonal. Under this simplest geometry, the resulting beam vector can easily be calculated. Note that the vector is strictly relative to the plane containing the two arrays with the X axis aligned along the transmitter (the $XY'$ plane from D18.5). Due to the magnitude of the beam vector $\\overrightarrow{bv_p}$ being one ($\\|\\overrightarrow{bv}\\|=1$), the offset in the $XY$ plane in the $X$-axis direction is $\\sin(\\text{tx}_\\text{steer})$ and in the $Y$-axis is $\\sin(\\text{rx}_\\text{steer})$. The radial distance in this plane is then $\\rho_{xy}=\\sqrt{\\sin(\\text{tx}_\\text{steer})^2+\\sin(\\text{rx}_\\text{steer})}$ and thus the distance $\\rho_{z}$ orthogonal to this plane is $\\rho_{z}=\\sqrt{1-\\rho_{xy}^2}$. Therefore the unit beam vector becomes:\n",
    "\n",
    "$$ \\overrightarrow{\\text{bv}_p}=\\left[ {\\begin{array}{cc}\\sin(\\text{tx}_\\text{steer}) \\\\\\sin(\\text{rx}_\\text{steer})\\\\\\sqrt{1-\\rho_{xy}^2}\\\\\\end{array} } \\right]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### D18.6.0  Formula for Intersection of Non-Orthogonal Arrays\n",
    " \n",
    "<img align=\"center\" width=\"80%\" style=\"padding-right:10px;\" src=\"./Images/non_ortho_concentric.jpg\">\n",
    "\n",
    "As a small extension of the previous case, if the receiver is oriented at an angle `non_ortho` away from 90 degrees to the transmitter, the formula is slightly different, but still easily calculated.\n",
    "\n",
    "$$y_1 = \\frac{\\sin\\phi_\\text{steer}}{cos(no)}$$<br>\n",
    "$$y_2 = \\sin(\\theta_\\text{steer})\\tan(no)$$<br>\n",
    "\n",
    "where:\n",
    "\n",
    "$\\theta_\\text{steer}$: Transmit steering angle<br>\n",
    "$\\phi_\\text{steer}$: Receive steering angle\n",
    "\n",
    "Given these offsets in the Y' direction we may determine the radial distance $\\rho_{hor}$ in the XY' plane as:\n",
    "\n",
    "$$\\rho_{hor}=\\sqrt{(y_1+y_2)^2+sin(\\theta_\\text{steer})^2}$$\n",
    "\n",
    "Use the steering angles $\\phi_\\text{steer}$ defined by the variable `-ping.steer_rx[i]` and $\\theta_\\text{steer}$ defined by the variable `ping.steer_tx[i]`. In the LabD.py script add and complete the following:\n",
    "\n",
    "    # D18.6.0  Formula for Intersection of Non-Orthogonal Arrays\n",
    "    y1=sin(...)/cos(...)\n",
    "    y2=sin(...)*tan(...)\n",
    "    radial=sqrt((...)**2+sin(...)**2)\n",
    "    \n",
    "Note that we have to use the negative of the steering angle provided in the data, due to the use of a different definition of positive beam steering than the one used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(\"\\n\\ny1:\")\n",
    "print(y1)\n",
    "print(\"\\ny2:\")\n",
    "print(y2)\n",
    "print(\"\\nradial:\")\n",
    "print(radial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    y1:\n",
    "    0.8437040803510717\n",
    "\n",
    "    y2:\n",
    "    -0.0002876541094044535\n",
    "\n",
    "    radial:\n",
    "    0.8440747190151341"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### D18.6.1  Formulate the Beam Vector `bv_p` in XYZ'\n",
    " \n",
    "\n",
    "We have now gotten to the point where we may define the beam vector relative to the transducer, or to be more precise the reference frame XYZ' defined by the transducer arrays.\n",
    "\n",
    "we will be consistent with the terminology used by Hughes Clarke and name this beam vector `bv_p`, though strictly speaking it is defined in a three dimensional space.\n",
    "\n",
    "In the new coordinate system the beam vector `bv_p` is given by:\n",
    "\n",
    "$$ \\overrightarrow{\\text{bv}}_\\text{geo}=\\text{T}_p\\overrightarrow{\\text{bv}}_p$$\n",
    "\n",
    "In the LabD.py script add and complete the following:\n",
    " \n",
    "    # D18.6.1  Formulate the Beam Vector `bv_p` in XYZ'\n",
    "    bv_p=np.array([[sin(...)],[...],[sqrt(1-radial**2)]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(\"\\n\\nbv_p:\")\n",
    "print(bv_p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    bv_p:\n",
    "    [[ -0.0333]\n",
    "     [ 0.8434]\n",
    "     [ 0.5362]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## D18.7 Transform the Beam Vector to Geo Referenced Space\n",
    " \n",
    "Currently the beam vector is transducer array relative, however to be able to apply ray tracing we need to align the beam to a georeferenced space in which the XY plane defines the horizontal and the Z axis defines the vertical. The matrix Tp defined in step D18.5 is the rotation matrix that achieves just this transformation:\n",
    "\n",
    "$$ \\overrightarrow{\\text{bv}}_\\text{geo} = \\text{T}_p\\overrightarrow{\\text{bv}}_p$$\n",
    "\n",
    "In our code we will use the variable `bv_g` to represent $\\overrightarrow{\\text{bv}}_\\text{geo}$ \n",
    "\n",
    "In the LabD.py script add and complete the following:\n",
    "\n",
    "    # D18.7 Transform the Beam Vector to Geo Referenced Space\n",
    "    bv_g=Tp@bv_p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(\"\\n\\nbv_g:\")\n",
    "print(bv_g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    bv_g:\n",
    "    [[ -0.0044]\n",
    "     [ 0.8573]\n",
    "     [ 0.5149]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D.18.8 Determine the Depression Angle of the Beam Vector\n",
    "\n",
    "<img align=\"center\" width=\"80%\" style=\"padding-right:10px;\" src=\"./Images/theta_az.bmp\">\n",
    "\n",
    "The depression angle $\\theta$ can now be determined from the georeferenced beam vector, it is the arctan of its z-component divided by its horizontal component i.e.:\n",
    "\n",
    "$$\\theta_\\text{beam} = \\arctan\\left(\\frac{\\text{bv}_\\text{geo,z}}{\\sqrt{\\text{bv}^2_\\text{geo,x}+\\text{bv}^2_\\text{geo,y}}}\\right)$$\n",
    "\n",
    "we will represent $\\theta_\\text{beam}$ by the variable `beam_th`\n",
    "\n",
    "In the LabD.py script add the following:\n",
    "\n",
    "    # D.18.8 Determine the Depression Angle of the Beam Vector\n",
    "    beam_th=float(arctan(bv_g[2]/sqrt(sum(bv_g[0:2]**2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(\"\\n\\nbeam_th:\")\n",
    "print(beam_th)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    beam_th:\n",
    "    0.5408497128145111\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D18.9 Determine the Azimuth of the Beam Vector\n",
    "\n",
    "The azimuth is the clockwise angle $\\alpha$ from North to the horizontal component of the vector i.e.,\n",
    "\n",
    "$$\\alpha_{hor} = \\arctan\\left(\\frac{bv_{geo,y}}{bv_{geo,x}}\\right)$$\n",
    "\n",
    "where the quadrant needs to be taken into account. Determine the azimuth of the beam and assign it to `beam_az`\n",
    "\n",
    "In the LabD.py script add the following:\n",
    "\n",
    "    # D18.9 Determine the Azimuth of the Beam Vector\n",
    "    beam_az=float(arctan2(...,...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(\"\\n\\nbeam_az:\")\n",
    "print(beam_az)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    beam_az:\n",
    "    1.575981901668627"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D19 At last: Ray Tracing\n",
    "\n",
    "We now have all the information that we need for the ray tracing, the sound speed at the transducer contained in the variable `ss_tx`, the starting depth `wl_virtual_trans[2]`, the depression angle `beam_th` and the travel time `ping.twtt[i]`\n",
    "\n",
    "Use the values above with the `SSP` `ray_trace_twtt` method to determine the depth $\\text{z}$ represented by the variable `depth` and radial distance $\\rho$ represented by the variable `rad_dist` for this beam.\n",
    "\n",
    "In the LabD.py script add and complete the following:\n",
    "\n",
    "    # D19 At last: Ray Tracing\n",
    "    depth,hor_dist,_,_ = ssp.ray_trace_twtt(...,...,...,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(\"\\n\\ndepth:\")\n",
    "print(depth)\n",
    "print(\"\\nradial distance:\")\n",
    "print(hor_dist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    depth:\n",
    "    [ 97.6591]\n",
    "\n",
    "    radial distance:\n",
    "    153.23034710155758"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D20 Positioning the Bottom Strike Relative to the Virtual Transducer\n",
    "\n",
    "Our penultimate step is the determination of where the bottom is relative to the position of the virtual transducer $\\overrightarrow{\\text{tx}}_v$ that we determined in step D17.4\n",
    "\n",
    "$$\\overrightarrow{\\text{bottom}}_\\text{vx}=\\left[ {\\begin{array}{cc}\\text{tx}_{v,x}+\\rho\\cos\\alpha \\\\\\text{tx}_{v,y}+\\rho\\sin\\alpha \\\\\\text{z}\\\\\\end{array} } \\right]$$\n",
    "\n",
    "In the LabD.py script add and complete the following:\n",
    "\n",
    "    # D20 Positioning the Bottom Relative to the Virtual Transducer\n",
    "    bot_vx = np.zeros((3,1))\n",
    "    bot_vx[0] = virtual_trans[0]+hor_dist*cos(beam_az)\n",
    "    bot_vx[1] = virtual_trans[...]+...*sin(...)\n",
    "    bot_vx[2] = depth    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(\"\\n\\nbottom relative to the virtual array:\")\n",
    "print(bot_vx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    bottom relative to the virtual array:\n",
    "    [[ 15.3628]\n",
    "     [ 151.4798]\n",
    "     [ 97.6591]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## D21 Positioning the Bottom Strike Relative to the RP at Transmit\n",
    "\n",
    "Our final step is the determination of where the bottom is relative to the position of the reference point rp at the time of transmission. To do this we can simply offset the virtual transducer horizontal coordinates by the virtual transducer location \n",
    "\n",
    "In the LabD.py script add and complete the following:\n",
    "\n",
    "    # D21 Positioning the Bottom Strike Relative to the RP at Transmit\n",
    "    bot_rp_tx = bot_vx.copy()\n",
    "    bot_rp_tx[0] -= virtual_trans[0]\n",
    "    bot_rp_tx[1] -= virtual_trans[1]\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i LabD.py\n",
    "\n",
    "print(\"\\n\\nbottom relative to the rp:\")\n",
    "print(bot_rp_tx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "Complete the following questions and submit the answers in a **WORD** document (please no *PDF* or other formats). If you do not have access to word please contact me first.\n",
    "\n",
    "Keep your answers concise, but they should consist of at least one full sentence.\n",
    "\n",
    "    1. How is the mismatch between the sound speed at the transducer addressed?\n",
    "    2. You would need to alter for use in the polar regions, why?\n",
    "        hint - this has to do with the positioning\n",
    "    3. Explain why the crab angle is not necessarily the negative value of the drift angle\n",
    "    4. Take the figure of D16 and show the drift angle associated to geo_pos_rp_rx\n",
    "    5. Even if the transducers are mounted perfectly orthogonal we typically still will find a non-orthogonality in our calculation of step D18.4, why is that?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
