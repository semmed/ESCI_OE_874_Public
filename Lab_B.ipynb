{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" width=\"12%\" style=\"padding-right:10px;\" src=\"./Images/Ccom.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Seabed Mapping Systems <a href=\"https://teams.microsoft.com/l/channel/19%3a178f95113a084a729f6c63b2f9e894c4%40thread.tacv2/Lab%2520B?groupId=b7209537-725b-40fc-bdbe-212e9689ef18&tenantId=d6241893-512d-46dc-8d2b-be47e25f5666\"><img src=\"./Images/help.png\"  title=\"Ask questions on Piazza.com\" align=\"right\" width=\"10%\" alt=\"https://teams.microsoft.com/\"></a><br><br>\n",
    "\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"./Images/refraction1.png\"><br><br>\n",
    "\n",
    "# B0 Lab intent\n",
    "\n",
    "\n",
    "This second lab is designed to encourage you to implement your own ray tracing algorithm for class `SSP`. This should be developed as a method for use in the last lab of the term (when you will have to ray trace 400-800 beams from a single swath cycle).\n",
    "\n",
    "That function will have as input:\n",
    "\n",
    "    1.A starting depression angle\n",
    "    2.A starting depth\n",
    "    3.A two-way travel time\n",
    "\n",
    "And from that you will calculate two things :\n",
    "\n",
    "    1.depth of the bottom strike\n",
    "    2.Radial distance out from transducer to the bottom strike\n",
    "    \n",
    "To help you understand the significance of sound speed variability, this lab will allow you to calculate:\n",
    "\n",
    "    •How long it should take for sound to travel from a transducer to a flat seafloor of a given depth\n",
    "    •How much of a depth (and radial distance error) would result if you use the wrong sound speed profile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B0.1 The Data\n",
    "\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"./Images/mvp.png\"><br><br>\n",
    "\n",
    "The profiles you will be using as examples are real measurements taken using a **<ins>M</ins>oving <ins>V</ins>essel <ins>P</ins>rofiler** (**MVP**). The model used was an ODIM MVP-300 (The system is now built and marketed by AML instead of ODIM). This system is designed  to take underway profiles of water column properties to a depth of up to ~300m from a vessel moving at 12 knots. The example data provided here is from a MVP-300 installed on the <ins>C</ins>anadian <ins>C</ins>oast <ins>G</ins>uard <ins>S</ins>hip (CCGS) Amundsen, Canada’s research icebreaker.\n",
    "\n",
    "This MVP-300 probe is equipped with a Seabird **<ins>C</ins>onductivity <ins>T</ins>emperature <ins>D</ins>epth**(**CTD**) 911+ sensor measuring **Conductivity** (proxy to salinity), **Temperature**, and pressure (proxy to **Depth**). From those measurements, the speed of sound in the water-column is modeled for use by the ship-mounted EM300 30 kHz multibeam sonar.\n",
    "\n",
    "The probe is dragged continuously behind the vessel at a depth just above the multibeam transducer. When released to free-fall, it falls at a speed of about $5 m/s$ and thus it takes about one minute to drop from near the surface to $300 m$. The limiting time however is that taken to winch back in the sensor. In that time, the vessel has moved forward $60\\cdot 6 m/s = 360 m$. Thus there is a total of $~700-800 m$ of cable deployed. The recovery speed is about $1 m/s$ so it takes about 10 minutes to get all the cable back in.\n",
    "\n",
    "It can thus deploy every ~15 minutes in depths of 300m if need be. For the example shown here it was set to cycle every 30 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"./Images/ssp_area.png\"><br><br>\n",
    "\n",
    "The example used in this lab here is a transect of 18 profiles taken at ½ hour intervals along a NE-SW transect across the Labrador Current. The section took 9 hours to acquire covering a total transit of ~110 nautical miles.\n",
    "\n",
    "The section covers from the main open Labrador Sea, onto the continental shelf where the Labrador Current is flowing from North to South, bringing cold brackish water from Baffin Bay down onto the Grand Banks.\n",
    "\n",
    "The area is of high survey significance to Canada when considering drilling on the Labrador Margin. The largest single impediment to drilling is the presence of huge icebergs that are swept down from Greenland in the Labrador Current. These icebergs carve giant grooves on the continental shelf and are thus an active hazard for oilfield infrastructure.\n",
    "\n",
    "Your challenge is to accurately survey the outer shelf (200-300m depth) with sufficient accuracy (let's say IHO Order 1 so ~+/-1% of depth). To achieve this accuracy you must have a reasonable approximation of the sound speed structure.\n",
    "\n",
    "This data set illustrates typical changes in that structure over a distance of ~6 nautical miles (1/2 and hour of ship time). Most ships **do not** have an MVP and thus sound speed profiles are usually only taken at intervals of 3-6 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B0.2 Temperature and Salinity Structure along the section\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"./Images/t_s_map.png\"><br><br>\n",
    "The figure above shows you the temperature and salinity structure along the section.\n",
    "\n",
    "Note the coldest and most brackish water in the south flowing Labrador current. That water is most brackish and slightly warmer at the surface. Cold and salty is more dense of course. Note however, that on the outer shelf there is a mid-water (~50-100m depth) temperature maximum with colder water above. If there were no other variation, this would be unstable as colder water should be heavier. But looking at the salinity we see that the surface waters are more brackish and thus make the water less dense even though it is colder.\n",
    "\n",
    "Indicated in the figure above are the locations of profiles 112 and 113 from which you have to do the calculations. Additionally, profiles 102 and 103 are also indicated. You will be asked what you think the influence of the change is there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B0.3 Derived Density and Sound Speed Structure\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"./Images/rho_ss_map.png\"><br><br>\n",
    "The plots above  are derived from the salinity and temperature structure shown in the previous section.\n",
    "\n",
    "The top plot is density and is derived using the **UNESCO equations**, knowing temperature, salinity and pressure. As can be seen the density structure most strongly mimics the salinity structure, indicating that the salinity is the more significant factor in density in this case.\n",
    "\n",
    "The lower plot is the sound speed which is derived using the Chen and Millero publication (again knowing temperature, salinity and pressure). In this case, the structure most closely resembles the temperature structure seen on the previous page. Thus clearly temperature is a greater influence on sound speed in this environment than salinity.\n",
    "\n",
    "As previously the locations of profiles 112 and 113, from which you have to do the calculations, are shown; profiles 102 and 103, where you are going to be asked what you think the influence of the change is, are also shown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### How much the Water Mass can change in ~½ an hour\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"./Images/ssps_over_time.png\"><br><br>\n",
    "\n",
    "The figure above illustrates two sequential MVP dips. In real time, you only have the last dip available to calculate the refracted ray path. Thus for the ~½ hour after the first dip has been acquired, all calculations are being performed using a water mass that is become increasingly out-of-date.\n",
    "\n",
    "After 40 minutes, a second dip takes place. You can see that the water-mass is remarkably different. Even though the near-surface sound speeds and the ones at ~250m depth are almost identical, for the majority of the profile, the newer dip reveals much lower sound speeds.\n",
    "\n",
    "Note that, while the near surface sound speeds are almost identical, the reason for them being this value is quite different. In the first cast it was due to cold-salty water. Now, almost the same sound speed value is being reported, but for warmer less salty water.\n",
    "\n",
    "How much does all this matter? In this lab, you will quantify the exact depth and radial distance error that results in from rays traced assuming the old water-mass, when if fact, the underlying water is the new water-mass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B0.4 Estimating the Refraction Error\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"./Images/refraction_error.png\"><br><br>\n",
    "\n",
    "To estimate the resulting error, you need to compare actual depth with the resultant erroneous depth. That error will vary both with total depth and incidence angle. As a result you need to pick a depth of interest (representative of the depth in which you are working). In this case we are picking a flat seabed at 250m depth. At that depth we then look at beams with incidence angles ranging from 0 (vertical incidence) to ~70 degrees (the widest you would be likely to attempt bottom detection).\n",
    "\n",
    "##### Calculating the true TWTT and the true Radial distance\n",
    "\n",
    "We need to find out the true TWTT and resulting radial distance that would result from beams over that range of incidence angles. To do that, one merely performs a ray trace, but in this special case the depth is known, but the TWTT is unknown (the reverse of the usual situation). Thus, you are tracing, keeping track of the TWTT accumulated until you arrive at your desired depth. As a result of this you will calculate an array of TWTTs and radial distances for the range of incidence angles you are testing for (for example 0 to 70 degrees at 1 degree intervals). You do this for the actual water-mass that you are really in.\n",
    "\n",
    "##### Calculating the Erroneous Depth and Radial Distance\n",
    "Now that you have this set of TWTTs , you use the usual forward calculation, tracing a ray through all the layers of the false sound speed profile until the TWTT is reached. You then compare the depth and across track distance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Lab Deliverables\n",
    "\n",
    "The deliverables for this lab are code that produces two plots with the X-axis being the true across track distance\n",
    "\n",
    "    1. With the vertical axis axis being the vertical error\n",
    "    2. With the vertical axis being the horizontal error\n",
    "    \n",
    "In addition you will be asked a number of essay questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B1 Reading the Sound Speed Profiles\n",
    "\n",
    "\n",
    "We will create a class to handle Sound Speed Profile (**SSP**) data. For convenience, we will add the class to the file ssp.py located in the same `mycode` folder where you created all the classes for Lab A.\n",
    "\n",
    "As usual we will do the import of all the packages at the top of the code file. \n",
    "\n",
    "*** \n",
    "<img align=\"left\" width=\"6%\" style=\"padding-right:10px;\" src=\"./Images/info.png\">It should be pointed out here that it is not strictly required to do the imports at the start of a code file; you can import packages as needed later. However, having the imports at the start is a good habit because it is easy to see the dependencies of this code on other code. You will not have to search through the, potentially, thousands lines of code to find the dependencies. It is not considered *Pythonesque* to have the imports in other places.\n",
    "***\n",
    "\n",
    "The next three lines to be added are pretty standard and you should be familiar with them by now - if not, then make sure to look them up immediately!\n",
    "\n",
    "    import os\n",
    "    from datetime import datetime, timezone\n",
    "    import numpy as np\n",
    "\n",
    "In this lab we will need to determine the arc-cosine of angles, as well as use various other mathematical functions. Make sure to add the following line to the top of `SSP.py`:\n",
    "    \n",
    "     from numpy import pi, cos, sin, log, exp, arccos, tan, arctan, tanh, arctanh\n",
    "\n",
    "The above leads this `Notebook` to default to the `numpy` implementation of the various mathematical functions listed.\n",
    "\n",
    "We will also need some of the functionality provided by the Position class - to this end also add the line:\n",
    "\n",
    "    from mycode.position import *\n",
    "    \n",
    "This will provide direct access to any class and function defined in the `position.py` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B1.0 Creating the SSP Class\n",
    "\n",
    "We will create a class with the ability to load and analyze a single **<ins>S</ins>ound <ins>S</ins>peed <ins>P</ins>rofile** (**SSP**). Note that we do not use the more common acronym SVP, where the <ins>V</ins> stands for *Velocity*. The reason for this is that SVP is a *misnomer* we observe sound speed as a **scalar** not a **vector**\n",
    "\n",
    "***\n",
    "<img align=\"left\" width=\"6%\" style=\"padding-right:10px;\" src=\"./Images/info.png\">\n",
    "A **vector** describes a quantity that may be characterized by the direction and magnitude in which it acts. <br>\n",
    "A **scalar** is then a quantity that has magnitude but lacks direction.<br>\n",
    "\n",
    "***\n",
    "\n",
    "What we report from observations, or model, is the magnitude of the velocity of a propagating sound wave i.e., a scalar value that is commonly referred to as **sound speed** or the **celerity of sound** (**c**).\n",
    "\n",
    "Create the class by entering the following lines:\n",
    "\n",
    "    class SSP:\n",
    "        \"\"\"A Class for handling Sound Speed Profile data\"\"\"\n",
    "\n",
    "        def __init__(self):\n",
    "            pass # Remove this line once you add code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B.2 Getting this Notebook Started\n",
    "\n",
    "The first code cell in any Notebook carries special importance. Though it is not a rule, it is a good habit to define your environment here. So-far this has always been done for you.\n",
    "\n",
    "The first two lines in the code cell below are:\n",
    "\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    \n",
    "The line `%load_ext autoreload` imports the `iPython` module `autoreload`, the line `%autoreload 2` \n",
    "causes all modules to reload (except those excluded by %aimport, which in this case are none) every time before executing the Python code typed - Note that this makes the Notebooks very inefficient, but makes it so that every time you save a change in the various `.py` files the effects take effect for all the subsequently executed lines of Python code, allowing your sanity to remain intact - changing and saving code in the `.py` files would otherwise have no effect until the `Kernel` is restarted!\n",
    "\n",
    "Next we will import the various packages created by 3<sup>d</sup> parties\n",
    "\n",
    "    import sys\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from numpy import cos,pi,sin,pi,arccos\n",
    "    from pathlib import Path\n",
    "\n",
    "Finally we will import code generated by us. The `mycode` directory is located in the same directory as this Notebook. The path on which the Notebook is located is the current path when working on the Notebook. The current path is the first location where an operation will look when searching files and directories, thus we do not even have to specify a path to our own code!\n",
    "\n",
    "    from mycode.ssp import SSP\n",
    "    \n",
    "We also want all the functionality provided by the code in the `positions.py file` in the `mycode` folder.\n",
    "     \n",
    "Note that if we keep all code in subdirectories of the current directory and use only relative paths to our current path it will make our code easily portable. Just know that there are also other, more complicated, methods to make your code portable; you may want to explore them once you start wanting to make subsets of your code available to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import cos,pi,sin,pi,arccos\n",
    "from pathlib import Path\n",
    "\n",
    "from mycode.position import *\n",
    "from mycode.ssp import SSP\n",
    "from mycode.analyzess import AnalyzeSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test whether everything went right by creating a `SSP` object named `ssp` and a `Position` object named `positions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp=SSP()\n",
    "positions = Position()\n",
    "print(positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    <mycode.ssp.SSP object at 0x7f0631c2c470>\n",
    "    geodetic_units: rad\n",
    "    height_units: m\n",
    "    proj_units: m\n",
    "    geoid_name: None\n",
    "    ellipsoid_name: None\n",
    "    height_relative_to: None\n",
    "    time_basis: UTC\n",
    "    proj_str: None\n",
    "    No height data present\n",
    "    No time data present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B3 Parsing the Sound Speed Profile Data\n",
    "\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"./Images/ssp_mvp_format.png\"><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## B3.0 The data content of the provided Sound Speed Profiles\n",
    "\n",
    "In the figure above you see the contents of two data files. We will need to create an data parser which is able to interpret the data collected with the MVP 300 System. You will find that often similar data are presented in very different ways to you, if your classes are well designed parsing these different data formats becomes an issue of simply adding read methods.\n",
    "\n",
    "The data in this MVP file is somewhat similar to the HYPACK data that you parsed if you did `Lab4_0` of the [*Tools for Ocean Mapping*] Course. If you do not already have the labs for that course click [here](https://epom0.hydroffice.org/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fsemmed%2FESCI_872_Public&urlpath=tree%2FESCI_872_Public%2F&branch=master), otherwise, if you are interested, you may proceed directly to [Lab4_0](../ESCI_872_Public/Lab4_0.ipynb). \n",
    "\n",
    "The similarity between the MVP files and the HYPACK data files lies in the fact that there is a file header containing lots of metadata about the data that is to follow. In the `SSP` case the data is a table containing columns of pressure, conductivity, temperature, sound speed, salinity and, density data. The pressure, conductivity and, temperature data are the *observed quantites*, whereas the sound speed, salinity and density data are *derived quantities*. Though it is often convenient to have derived quantities it often is advisable to rely on the observed quantities, or as they are often called: **raw data**.  \n",
    "\n",
    "As can be seen from the figure above, the sensor is integrated with the shipboard navigation so that the following data are recorded in the header:\n",
    "\n",
    "    1.Launch Location\n",
    "    2.Time of launch\n",
    "    3.Speed of vessel at launch\n",
    "    4.Depth at launch location\n",
    "\n",
    "All these are derived from [NMEA-0183](https://en.wikipedia.org/wiki/NMEA_0183) datagrams (which are automatically preserved in the file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### B3.0.0 Add Attribute Variables to the SSP class\n",
    "\n",
    "<img align=\"left\" width=\"6%\" style=\"padding-right:10px;\" src=\"./Images/test.png\">\n",
    "\n",
    "Update the SSP `__init__` by adding the following attributes with initial value `None`:\n",
    "\n",
    "     self.obs_time = \n",
    "     self.log_time = \n",
    "     self.vessel_speed = \n",
    "     self.bot_depth = \n",
    "     \n",
    "Add two position objects:\n",
    "\n",
    "    self.pos_obs = \n",
    "    self.pos_vessel = \n",
    "\n",
    "Also, add the following attributes as empty `lists`:\n",
    "\n",
    "    self.obs_depths = \n",
    "    self.obs_sample = \n",
    "    self.obs_ss = \n",
    "\n",
    "Then add the following empty `numpy` array attributes:\n",
    "\n",
    "    self.proc_depth = \n",
    "    self.proc_ss = \n",
    "    self.twtt_g = \n",
    "\n",
    "Finally, add the `metadata` `dictionary` as below:\n",
    "\n",
    "    self.metadata = dict()\n",
    "    self.metadata[\"angle_units\"] = \"rad\"\n",
    "    self.metadata[\"distance_units\"] = \"m\"\n",
    "    self.metadata[\"speed_units\"] = \"m/s\"\n",
    "    self.metadata[\"time_units\"] = \"s\"\n",
    "    self.metadata[\"count\"] = None\n",
    "    self.metadata[\"geoid\"] = None\n",
    "    self.metadata[\"ellipsoid\"] = None\n",
    "    self.metadata[\"chart_datum\"] = None\n",
    "    self.metadata[\"time_basis\"] = \"UTC\"\n",
    "    self.metadata[\"name\"] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B3.1 Extract the Header of the MVP Data Files\n",
    "\n",
    "Add the method `read_mvp_file` to the SSP class. If done correctly the code cell below will show you the contents of the MVP data file \"Oct4_slope.112m1.mvp\" found in your \"Data\" directory for Lab B.\n",
    "\n",
    "    def read_mvp_file(self, fullpath):\n",
    "\n",
    "        # Check to see whether data already exists in the object\n",
    "        \n",
    "        if self.obs_depth:\n",
    "            raise RuntimeError('SSP object already contains a profile')\n",
    "\n",
    "        # Check the File's existence\n",
    "        print(fullpath)\n",
    "        \n",
    "        if os.path.exists(fullpath):\n",
    "            self.metadata[\"Source File\"] = fullpath\n",
    "            print('Opening sound speed profile data file:' + fullpath)\n",
    "        else:  # Raise a meaningful error\n",
    "            raise RuntimeError('Unable to locate the input file' + fullpath)\n",
    "\n",
    "        # Open, read and close the file\n",
    "        svp_file = open(fullpath)\n",
    "        svp_content = svp_file.read()\n",
    "        svp_file.close\n",
    "        \n",
    "        # Save the file name as meta data\n",
    "        \n",
    "        self.metadata[\"name\"] = os.path.basename(fullpath)\n",
    "\n",
    "        # Tokenize the contents\n",
    "        svp_lines = svp_content.splitlines()\n",
    "        \n",
    "        n_header_lines = 0\n",
    "        for line in svp_lines:\n",
    "            print(line) # Remove after step B3.1 has been successfully completed\n",
    "\n",
    "            n_header_lines += 1\n",
    "            \n",
    "            if line == '':\n",
    "                break\n",
    "Note the use of the line counter `n_header_lines`. So-far `SSP.read_mvp_file` method will read the entire file and then print its contents line-by-line until an empty line is encountered "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp=SSP()\n",
    "ssp.read_mvp_file('Data/Oct4_slope.112m1.mvp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B3.2 How we Found the End of The Header\n",
    "\n",
    "What you will notice is that the code cell above printed the contents of the header, except for the line that indicates the data format in the table to follow. In our case we will read the data file in three parts, first the header, then the parsing format string and then, the data records. Rather than processing the raw data (which would be a lab on its own) we will use the derived data.\n",
    "\n",
    "***\n",
    "<img align=\"left\" width=\"6%\" style=\"padding-right:10px;\" src=\"./Images/key.png\"><br>\n",
    "by using the derived data **we may be in error**! Note that the survey latitude is indicated at 45<sup>o</sup>N, but that the actual survey is closer in latitude to 56<sup>o</sup>N. If some of the modeling used to create derived quantities depends on the survey latitude then it will have some latitude dependent systematic error.\n",
    "\n",
    "***\n",
    "A simple way of reading just the header would have been to `break` out of the execution of the for loop when the line 'P(dbar),C(mmho/cm),T(degC),Dpth(m),SV(m/s),S(PSS-78),Rho(kg/m^3)' is encountered. The problem with this is that for the MVP 30 the contents of data records depend on the installed sensors; which means that the contents of this line may vary. However, the line describing the records is alway preceded by an empty line; we use this to recognize the end of the header part of the data file.\n",
    "\n",
    "Break the loop when the contents of `line` are equivalent to '', that is, the line is an empty string. If you now run the code cell above it should show you just the contents of the header, except for the last line: *P(dbar),C(mmho/cm),T(degC),Dpth(m),SV(m/s),S(PSS-78),Rho(kg/m^3)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B3.3 Create a Function for Parsing `ZDA` Time Datagrams\n",
    "\n",
    "Upon inspection you will see that the header contains more than one record indicating time. The PC Time is problematic since it may be in any time zone and the clock may not be very accurate. The **GNSS** time contained in **NMEA-0183** records is much more accurate and always referenced to **UTC**. There is a dedicated NMEA-0183 time message known as  **ZDA**. It does make sense to add a `function` to the `position.py` file that takes a ZDA NMEA message and returns a datetime object. Technically it would be better to create a `nmea.py` file dedicated to NMEA datagrams - we will not do this here to keep our code simpler. If you do a little research you will find that *Eric S. Raymond* created a whole module dedicated to NMEA-0183 that you may retrieve [here](https://gpsd.gitlab.io/gpsd/NMEA.html)\n",
    "    \n",
    "In the `position.py` file add the following `function` at the end. \n",
    "\n",
    "    def ParseNMEA0183_ZDA( dt_str):\n",
    "    obs = dt_str.split(',')\n",
    "    time = datetime( \n",
    "        int( obs[4]), \n",
    "        int( obs[3]), \n",
    "        int( obs[2]), \n",
    "        int( obs[1][0:2]), \n",
    "        int( obs[1][2:4]), \n",
    "        int( obs[1][4:6]),\n",
    "        int(obs[1][7:])*10000)\n",
    "    return time       \n",
    "        \n",
    "To understand what the code above does please visit this [ZDA](https://gpsd.gitlab.io/gpsd/NMEA.html#_zda_time_date_utc_day_month_year_and_local_time_zone) definition, as well as the official python `datetime` documentation. \n",
    "        \n",
    "**NOTE**, this is a *function* **NOT** a class *method* i.e. it the `def` statement should be aligned **all** the way to the left in the file. \n",
    "\n",
    "Also note, the GGA and ZDA times in the header mismatch by one second! This is a known bug for the MVP 300 and, in the case of sound speed profiles, not significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B3.4 Find the Time, Position, Depth and, Speed Strings\n",
    "\n",
    "Before we move on, remove the print statement in the `for` loop created in step B3.1, unless you want to see the contents of the header every time we read the file.\n",
    "\n",
    "While we have not have broken out of the for loop yet we are still parsing the header i.e., any statements that follow:\n",
    "\n",
    "    if line == '':\n",
    "        break\n",
    "\n",
    "in the for loop of step B3.1 will *only* be executed while still parsing the header.\n",
    "\n",
    "Remember that NMEA GGA strings do not contain a date. It is not a given that there will be a date in the header before the vessel position (in our example there is not). That means that we need a to recover a date before processing the GGA record indicating our position. It makes sense to collect all the header data that we need first and then process it in an order that guarantees that we have the prerequisite data:\n",
    "\n",
    "    # Find and extract the time string\n",
    "    if \"gps time\" in line.lower():\n",
    "        # Extract the ZDA record\n",
    "        obs_time = line.split()[2]\n",
    "\n",
    "    # Find and extract the position string\n",
    "    if \"gps position\" in line.lower():\n",
    "        # Extract the GGA record\n",
    "        obs_pos = line.split()[2]\n",
    "\n",
    "    # Find and extract the depth string\n",
    "    if \"bottom depth\" in line:\n",
    "        obs_depth = line.split()[2]\n",
    "\n",
    "    # Find and extract the vessel speed string\n",
    "    if line[0:11] == \"Ship Speed:\":\n",
    "        obs_vessel_speed = line.split()[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp=SSP()\n",
    "ssp.read_mvp_file('Data/Oct4_slope.112m1.mvp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Data/Oct4_slope.112m1.mvp\n",
    "    Opening sound speed profile data file:Data/Oct4_slope.112m1.mvp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B3.5 Check to see if There is a Date and Time\n",
    "\n",
    "We only should move on if we found, what in the header is referred to as, a *gps time*:\n",
    "\n",
    "    if 'obs_time' not in locals():\n",
    "        raise RuntimeError('SSP.read_mvp_file(): Missing date and time info!')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp=SSP()\n",
    "ssp.read_mvp_file('Data/Oct4_slope.112m1.mvp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Data/Oct4_slope.112m1.mvp\n",
    "    Opening sound speed profile data file:Data/Oct4_slope.112m1.mvp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B3.6.1 Parse the Time\n",
    "\n",
    "We now have the required data, but it is still in string form. We will have to parse the strings before moving on.\n",
    "\n",
    "We will start with the time, for which we will use the function `ParseNMEA0183_ZDA` that we just created:\n",
    "\n",
    "    self.obs_time = ParseNMEA0183_ZDA(obs_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp=SSP()\n",
    "ssp.read_mvp_file('Data/Oct4_slope.112m1.mvp')\n",
    "print(ssp.obs_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Data/Oct4_slope.112m1.mvp\n",
    "    Opening sound speed profile data file:Data/Oct4_slope.112m1.mvp\n",
    "    2004-10-04 17:27:05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B3.6.2 Parse the Position\n",
    "\n",
    "If you think about it there are two positions associated to the SSP profiles, namely the location of the vessel and the location of the probe that is towed behind the vessel at a distance that we refer to as **lay-back**. To deal with this the SSP class has the attribute `SSP.pos_obs` to indicate the location of the probe, and `SSP.pos_vessel` to indicate the location of the vessel. Unfortunately there is only one position in these files, namely the vessel position; there is no indication of what the lay-back used was. We will just leave the  \n",
    "`SSP.pos_obs` attributes at their default values. That way if someone tries to use the SSP class object they are aware that there is no proper position for the actual profile.\n",
    "\n",
    "Set the `SSP.pos_vessel` by adding the code:\n",
    "\n",
    "    self.pos_obs.ParseNMEA0183_GGA(\n",
    "                obs_pos,\n",
    "                \"EGM08\",\n",
    "                \"WGS84\", \n",
    "                \"geoid\", \n",
    "                self.obs_time)\n",
    "\n",
    "Note that if you do this lab in 2021 you probably will be rewarded with a `NameError`. If that is the case you will have to update the code that was created in `positions.py` in Lab4 step 4.10 to\n",
    "\n",
    "    # If there is more data then parse it\n",
    "    corr_age = None\n",
    "    corr_station = None\n",
    "    if not gga_data[13] == \"\":\n",
    "        self.corr_ages.append(float(gga_data[13]))\n",
    "        self.corr_stations.append(float(gga_data[14][0:-3]))\n",
    "\n",
    "Ask yourself: Do you understand what caused the error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp=SSP()\n",
    "ssp.read_mvp_file('Data/Oct4_slope.112m1.mvp')\n",
    "print(ssp.pos_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Data/Oct4_slope.112m1.mvp\n",
    "    Opening sound speed profile data file:Data/Oct4_slope.112m1.mvp\n",
    "    geodetic_units: rad\n",
    "    height_units: m\n",
    "    proj_units: m\n",
    "    geoid_name: EGM08\n",
    "    ellipsoid_name: WGS84\n",
    "    height_relative_to: geoid\n",
    "    time_basis: UTC\n",
    "    proj_str: None\n",
    "    Minimum latitude       : 55.956316\n",
    "    Maximum latitude       : 55.956316\n",
    "    Minimum longitude      : -57.693735\n",
    "    Maximum longitude      : -57.693735\n",
    "    Minimum height         : 27.91m\n",
    "    Maximum height         : 27.91m\n",
    "    Start Time             : 2004-10-04 17:27:06\n",
    "    End Time               : 2004-10-04 17:27:06\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B3.6.3 Parse the Depth\n",
    "\n",
    "The depth stored in the header is the depth that the MVP estimates for the location of the probe. It is used to govern how far the probe is lowered. Clearly a safety margin should be (and is) used to avoid the probe hitting the bottom. As the probe is towed by the vessel it stands to reason that the vessel goes over the location of the probe shortly before. Thus with an estimate of the lay-back position it is possible to estimate the depth at the location of the probe.\n",
    "\n",
    "    self.bot_depth=float(obs_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp=SSP()\n",
    "ssp.read_mvp_file('Data/Oct4_slope.112m1.mvp')\n",
    "print(ssp.bot_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Data/Oct4_slope.112m1.mvp\n",
    "    Opening sound speed profile data file:Data/Oct4_slope.112m1.mvp\n",
    "    278.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B3.6.4 Parse the Speed\n",
    "\n",
    "The speed through the water is an important part for the engineering management of the MVP system, we will also retrieve it from the header as it gives some insight in the operational conditions of when the data was collected.\n",
    "\n",
    "    self.vessel_speed=float(obs_vessel_speed)*1852/3600\n",
    "    \n",
    "Ask yourself: why are we scaling by 1852/3600 and what do you think the resultant units are? If you cannot think of an answer post a message on [Teams](https://teams.microsoft.com/l/channel/19%3a178f95113a084a729f6c63b2f9e894c4%40thread.tacv2/Lab%2520B?groupId=b7209537-725b-40fc-bdbe-212e9689ef18&tenantId=d6241893-512d-46dc-8d2b-be47e25f5666) so that your peers may help you out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp=SSP()\n",
    "ssp.read_mvp_file('Data/Oct4_slope.112m1.mvp')\n",
    "print(ssp.vessel_speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Data/Oct4_slope.112m1.mvp\n",
    "    Opening sound speed profile data file:Data/Oct4_slope.112m1.mvp\n",
    "    6.070444444444445"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B3.7 Parsing the Record Identifier Line\n",
    "\n",
    "Now that we have parsed the metadata in the header the next job is to parse the last line of the header. This line identifies the type and units of the data contained in the columns of the data records.\n",
    "\n",
    "The first step is to split the last header line\n",
    "\n",
    "        rec_type = svp_lines[n_header_lines].split(',')         \n",
    "\n",
    "for our data this result in: \n",
    "\n",
    "    ['P(dbar)', 'C(mmho/cm)', 'T(degC)', 'Dpth(m)', 'SV(m/s)', 'S(PSS-78)', 'Rho(kg/m^3)']\n",
    "    \n",
    "We will use the derived quantities Depth, identified by the `string` `'Dpth(m)'`, and sound speed, identified by the `string` `'SV(m/s)'` i.e., the data in the 4<sup>th</sup> and 5<sup>th</sup> columns. Given the fact that the format is not fixed we do not want to hard-code these columns, but rather parse the list `rec_type` and determine from that what the order of the columns in this particular data file are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B.3.7.0 Find the Index of the `'Dpth(m)'` Column\n",
    "\n",
    "To find the index of the **depth** column we can then use:\n",
    "\n",
    "    index_depth = rec_type.index('Dpth(m)') \n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B.3.7.1 Find the Index of the `'SV(m/s)'` Column\n",
    "\n",
    "Similarly, to find the index of the **sound speed** records we can then use:\n",
    "\n",
    "    index_ss = rec_type.index(...)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp=SSP()\n",
    "ssp.read_mvp_file('Data/Oct4_slope.112m1.mvp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Data/Oct4_slope.112m1.mvp\n",
    "    Opening sound speed profile data file:Data/Oct4_slope.112m1.mvp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B3.8 Parsing the Records\n",
    "\n",
    "We can finally parse the data!  \n",
    "\n",
    "        for line in svp_lines[ n_header_lines + 1:]:\n",
    "            obs = line.split(',')\n",
    "            self.obs_depth.append( float(obs[index_depth]))\n",
    "            self.obs_ss.append( float(obs[index_ss]))\n",
    "\n",
    "Will read all the data records into the `SSP` data object.\n",
    "\n",
    "***\n",
    "\n",
    "<img align=\"left\" width=\"6%\" style=\"padding-right:10px;\" src=\"./Images/key.png\"><br>\n",
    "Note that in the code cell below we make use of the `zip` command. `zip` takes as its arguments a set of iterators. Python `iterators` are objects that you may iterate through using e.g., a `for` loop. An example of an iterator is then a `list`. If you can index a variable holding a set of values to get at a specific value then, by definition, the variable is an `iterator`\n",
    "\n",
    "The `zip()` function takes `iterators` as arguments  and returns a zip object, which is an iterator of tuples where the item at the same index in each passed-in `iterator` are paired together. If the iterators that are passed in have different length the `zip` object will have the dimension of the shortest of the iterators passed in.\n",
    "\n",
    "***\n",
    "\n",
    "`zip` objects are convenient when we want to simultaneously iterate through a set of `iterators`, as shown in the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp=SSP()\n",
    "ssp.read_mvp_file('Data/Oct4_slope.112m1.mvp')\n",
    "for d,c in zip(ssp.obs_depths, ssp.obs_ss):\n",
    "    print( 'Depth:%5.2fm C:%7.2fm/s'%(d,c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Data/Oct4_slope.112m1.mvp\n",
    "    Opening sound speed profile data file:Data/Oct4_slope.112m1.mvp\n",
    "    Depth: 6.84m C:1463.92m/s\n",
    "    Depth: 6.55m C:1463.91m/s\n",
    "    Depth: 7.04m C:1463.91m/s\n",
    "    Depth: 6.55m C:1463.90m/s\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B3.9 Sorting the Records\n",
    "\n",
    "Although we now have all the data, it is not a given that the data in the profile are sorted by depth. This is easily observed in the output of the code cell above. The records are written sequentially in time and so, *usually* each subsequent record has a greater depth associated to it. This is, however, not guaranteed! It may be that the MVP winch moved faster upwards than the probe was falling through the water, leading to a reversal in the recorded depths. To make sure that this is not the case you should sort the profile's observed depths and sound speeds by depth.\n",
    "\n",
    "***\n",
    "<img align=\"left\" width=\"6%\" style=\"padding-right:10px;\" src=\"./Images/key.png\"><br>\n",
    "To sort an iterable we may use `sorted`, whose use is as follows: sorted(iterable, key=key, reverse=reverse)\n",
    "\n",
    "in our case we want to sort the sound speeds by depths, thus we zip them together and use the zip object as the `iterable` for the `sorted` function. We want to sort by the depths which is the first of the values in the `zip` object tuples. In order to do this we create a function `lambda x: x[0]` that, in this case returns the value at the first index of the tuple i.e., the depth\n",
    "\n",
    "\n",
    "this is achieved by the following code that sorts both lists simultaneously by the contents of the list `self.obs_depth`:\n",
    "\n",
    "        temp = sorted(zip(self.obs_depths, self.obs_ss), key=lambda x: x[0])\n",
    "        \n",
    "In the code cell below you can see the result of this type of operation (compare it with the output of the code cell above and you see that the data are now sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = sorted(zip(ssp.obs_depths, ssp.obs_ss), key=lambda x: x[0])\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    [(6.25, 1463.89),\n",
    "     (6.35, 1463.89),\n",
    "     (6.55, 1463.91),\n",
    "     (6.55, 1463.9),\n",
    "     (6.65, 1463.87),\n",
    "     (6.65, 1463.86),\n",
    "     (6.74, 1463.86),\n",
    "     ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are however not done, we want to create the lists `processed_depths` and  `processed_ss` ordered by depth. The problem is that we now have a `list` `temp` of `tuples` as can be seen from the code cell above. What we want to do is to `unpack` each `tuple`, i.e., turn them into, in this case, two values. We achieve this using the unpacking operator `*`. This results in two iterables that can be zipped together. We then use the `map` function to maneuver through the resulting `zip` iterable object and extract the data as `lists`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of unpacking a list of tuples temp\n",
    "temp = sorted(zip(ssp.obs_depths, ssp.obs_ss), key=lambda x: x[0])\n",
    "print(type(temp))\n",
    "print(type(temp[0]))\n",
    "print(type(zip(*temp)))\n",
    "print(map(list,zip(*temp)))\n",
    "depths,speeds = map(list,zip(*temp))\n",
    "for d,c in zip(depths, speeds):\n",
    "    print( 'Depth:%5.2fm C:%7.2fm/s'%(d,c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the following line to unpack the depths and sound speeds and re-assign them to their respective `lists` : \n",
    "\n",
    "    proc_depths, proc_ss = map(list, zip(*temp))\n",
    "    \n",
    "The lists `processed_depths` and `processed_ss` are local variables - we do not want to replace the lists `SSP.self.obs_depths` and `SSP.obs_ss` as they are the raw data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B3.10 Removing the Duplicates\n",
    "\n",
    "Much like there may be reversals, there may be duplicates;  depths for which there is more than one observation. You may see this in the output of the code cell above e.g., there are two sound speeds for a depth of 6.55m! There are several approaches that you may take to deal with this. Ideally the sound speed values will be the same, but in reality they will probably differ slightly, as they do in the output of the code cell above. This is actually an opportunity for quality control.\n",
    "\n",
    "However, for the sake of keeping the scope of the lab limited we will take a simple approach here by taking the first observation and removing the others, this may be achieved by adding the following to the end of the `read_mvp_file()` method:\n",
    "\n",
    "    d_p=processed_depths[0]\n",
    "    index = 0\n",
    "    unwanted = []\n",
    "    for d in processed_depths[1:]:\n",
    "        index += 1\n",
    "        if d  == d_p:\n",
    "            unwanted.append(index)\n",
    "        d_p = d\n",
    "\n",
    "    for e in sorted( unwanted, reverse = True):\n",
    "        del processed_depths[ e]\n",
    "        del processed_ss[ e]\n",
    "\n",
    "Make sure that you understand the code snippet given here and ask yourself why the duplicates should be removed in reverse order - you will be asked about this as one of your deliverables for this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B3.11 Creating numpy Arrays of Data for Processing\n",
    "\n",
    "For further processing it will be useful to use numpy arrays - For now we will use 2 of these arrays, namely `SSP.proc_depth` and `SSP.proc_ss` to hold the depths and the associated sound speeds respectively.\n",
    "\n",
    "    self.proc_depth = np.array(processed_depths)\n",
    "    self.proc_ss = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp=SSP()\n",
    "ssp.read_mvp_file('Data/Oct4_slope.112m1.mvp')\n",
    "for d,c in zip(ssp.proc_depth, ssp.proc_ss):\n",
    "    print( 'Depth:%5.2fm C:%7.2fm/s'%(d,c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Data/Oct4_slope.112m1.mvp\n",
    "    Opening sound speed profile data file:Data/Oct4_slope.112m1.mvp\n",
    "    Depth: 6.25m C:1463.89m/s\n",
    "    Depth: 6.35m C:1463.89m/s\n",
    "    Depth: 6.55m C:1463.91m/s\n",
    "    Depth: 6.65m C:1463.87m/s\n",
    "    Depth: 6.74m C:1463.86m/s\n",
    "    Depth: 6.84m C:1463.92m/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B3.12 Extend the Profiles to the Surface\n",
    "    \n",
    "A problem that may occur is the transducer rising above the level of the first sound speed observation. To address this we should extend the profile to the surface. To extend the velocities to the surface we face a bit of a conundrum as we do not have an observed value there i.e., we are extrapolating. However, we do know that sound velocity profiles typically start close the surface and that surface waters are *usually* well mixed due to wave action. Thus, we may reasonably expect that the sound speed at the surface is the same as at the first sample in the profile:\n",
    "    \n",
    "        if self.d[0] > 0:\n",
    "            self.d = np.insert(self.d,0,0)\n",
    "            self.c = np.insert(self.c,0,self.c[0])\n",
    "    \n",
    "Note that this assumption **fails** when there is no mixing at the surface - this is one of the reasons that surveying on calm seas can be problematic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp=SSP()\n",
    "ssp.read_mvp_file('Data/Oct4_slope.112m1.mvp')\n",
    "for d,c in zip(ssp.proc_depth, ssp.proc_ss):\n",
    "    print( 'Depth:%5.2fm C:%7.2fm/s'%(d,c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Data/Oct4_slope.112m1.mvp\n",
    "    Opening sound speed profile data file:Data/Oct4_slope.112m1.mvp\n",
    "    Depth: 0.00m C:1463.89m/s\n",
    "    Depth: 6.25m C:1463.89m/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B3.13 Calculate the Sound Speed Gradients\n",
    "  \n",
    "The propagation path that a sound signal follows through the water column is density driven. Variation in the density of the water lead to variations in sound speed, and the curvature of the propagation path at any point may be modeled using the local sound speed gradient.\n",
    "\n",
    "The gradient of a field at a point is the vector pointing in the direction of the greatest change with a magnitude equal to the change. Thus for sound speed in a Cartesian 3D standard basis right-handed coordinate system the gradient is:\n",
    "\n",
    "$$\\overrightarrow{g_t}=\\nabla c_t= \\sum_{i=1}^{3}\\overrightarrow{e_i}\\frac{\\delta{c_t}}{\\delta x_i} = \\left(\\frac{\\delta{c_t}}{\\delta x_1}, \\frac{\\delta{c_t}}{\\delta x_2}, \\frac{\\delta{c_t}}{\\delta x_3}\\right)$$\n",
    "\n",
    "where:<br>\n",
    "$t$: epoch<br>\n",
    "$\\overrightarrow{g_t}$: Sound speed gradient at $t$<br>\n",
    "$\\nabla:$ Vector differential operator (known as **Del** or **Nabla**)<br>\n",
    "$c_t=c_t(x_1,x_2,x_3)$: Sound speed at $t$ <br>\n",
    "$\\overrightarrow{e_i}=\\{\\overrightarrow{e_1}, \\overrightarrow{e_2}, \\ldots, \\overrightarrow{e_n}\\}$ Basis for coordinate system\n",
    "\n",
    "It is impractical to determine the gradient of sound speed for almost any volume at a certain epoch. It is physically impossible to get enough sound speed samples at a high enough resolution within a short enough time span.\n",
    "\n",
    "**Oceanographic Simplifications**\n",
    "\n",
    "Normally, the only sound speed profile information consists of a vertical section. No knowledge of the lateral variability of sound speed in the ocean is available. As a result, a simplifying assumption is usually made that the ocean consists only of horizontal layers with no lateral variability i.e., the gradient is one dimensional and occurs in the direction of depth. The primary result of this assumption is that the beam azimuth will remain constant: that the ray only changes in depression angle as it penetrates through the layers and that the gradient may be represented by just its magnitude (for 1D vectors $\\lVert \\overrightarrow{g_t} \\lVert = \\overrightarrow{g_t} = g_t$ i.e., the vector is a scalar)\n",
    "\n",
    "In reality, there are significant lateral sound speed gradients in the ocean. These can include: Oceanic fronts (e.g. the edge of the Gulf Stream or Kuroshiro) Tidal fronts (representing the boundary between mixed and stratified waters), river plume edges, etc.\n",
    "\n",
    "The only way to cope with these is to make more frequent sound speed profiles. As time evolves or the ship moves, the ocean is changing. There are strategies to gradually adjust the sound speed with space or time, but even under these circumstances, there is one simplifying assumption that is commonly made:\n",
    "\n",
    "##### For the duration of a single ping, the sound speed structure does not change with azimuth. That is to say, a ray traced to the north, versus a ray to the west (or other azimuth), does not follow a different trajectory in the vertical plane.\n",
    "<br>\n",
    "The above assumption allows us to model the water as vertically stratified i.e., the sound speed varies as a function of depth, but not location. Thus for our sound speed model the gradient vector points either up or down and may be completely characterized by its magnitude. Also, we are typically able to sample over a depth interval in which the sound speed does not vary significantly, thus we may approach the gradient by differencing the observations; as a result we may ensure that the array `self.g` will represent the gradient of sound-speed for the layers $i$, that is:\n",
    "\n",
    "$$g_i = \\frac{\\Delta c_i}{\\Delta d_i}=\\frac{c_{i+1}-c_{i}}{d_{i+1}-d_{i}}$$\n",
    "\n",
    "Thus for a sound speed $c$ increasing with depth $d$ the gradient is positive.\n",
    "\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"./Images/layer_indexing.png\"><br><br>\n",
    "As the indexing may get confusing it is helpful to look at the image above: layer $i$ spans $d_i$ to $d_{i+i}$ and has gradient $g_i$\n",
    "\n",
    "You can implement $c_{i+1}-c_{i}$ as `self.c[1:] - self.c[0:-1])` or equivalently as `np.diff(self.c)` without having to use a for loop; the depth differences may be determined similarly.\n",
    "\n",
    "    # B3.13 Calculate the Sound Speed Gradients\n",
    "    self.g = ...\n",
    "    \n",
    "Note that despite the slightly lower performance of `np.diff(self.c)` I prefer that annotation; it serves a reminder to the coder that we are doing differential operations and thus the output `iterator` will have one value less than the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp=SSP()\n",
    "ssp.read_mvp_file('Data/Oct4_slope.112m1.mvp')\n",
    "print(ssp.g[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Data/Oct4_slope.112m1.mvp\n",
    "    Opening sound speed profile data file:Data/Oct4_slope.112m1.mvp\n",
    "    [ 0.          0.1        -0.4        -0.11111111  0.6        -0.05\n",
    "     -0.6         0.6        -0.5       ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B3.14 Expanding the Profiles to Full Ocean Depth\n",
    "  \n",
    "We also want to expand the profile to full ocean depth in case we have depth observations beyond the deepest sound speed sample. We may achieve this by making the assumption that the gradient is determined by the pressure effect alone (g=0.017$s^{-1}$). Add a block of code that adds the full ocean depth of 12,000m to the end of array `self.proc_depth`, the associated sound speed calculated using the gradient g=0.017$s^{-1}$ to the array `self.proc_ss` and the gradient used to the array `self.g`. **Only** do this if the greatest depth in the profile is smaller than 12,000m:\n",
    "\n",
    "    if self.proc_depth[-1] < ...:\n",
    "        self.proc_depth = np.append(self.proc_depth,...)\n",
    "        self.proc_ss = np.append(self.proc_ss, self.proc_ss[...] \\\n",
    "                       + 0.017 * (12000 - self.proc_depth[...]))\n",
    "        self.g = np.append(self.g,0.017)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp=SSP()\n",
    "ssp.read_mvp_file('Data/Oct4_slope.112m1.mvp')\n",
    "print(ssp.proc_depth[-10:])\n",
    "print(ssp.proc_ss[-10:])\n",
    "print(ssp.g[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Data/Oct4_slope.112m1.mvp\n",
    "    Opening sound speed profile data file:Data/Oct4_slope.112m1.mvp\n",
    "    [  264.86   265.06   265.36   265.55   265.85   266.05   266.15   266.35\n",
    "       266.64 12000.  ]\n",
    "    [1475.42    1475.43    1475.43    1475.43    1475.44    1475.44\n",
    "     1475.44    1475.45    1475.45    1674.91712]\n",
    "    [0.03333333 0.05       0.         0.         0.03333333 0.\n",
    "     0.         0.05       0.         0.017     ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B3.15 Replacing Zero Gradients\n",
    "  \n",
    "For our calculations we will be dividing by the gradients. To avoid numerical problems we can test the gradient and act accordingly, however this makes the resulting code confusing and slow. Alternatively we can replace zero values by very small numbers, accepting the very small changes in the modeling. This is perfectly acceptable, simpler and, significantly faster, but only as long as we keep the replacement number a couple of orders of magnitude lower than the measurement uncertainty associated to the modeled gradient \n",
    "\n",
    "    self.g[self.g == 0] = 10**-9\n",
    "    \n",
    "Note that the above is making clever use of **Boolean** indexing. `self.g == 0` results in an `iterable` (numpy array in this case) of length `len(self.g)` with the values set to `True` where the corresponding values in `self.g` equal zero, and `False` everywhere else. You may use a Boolean `iterable` of equal length to an `iterable` of interest to select the values in the `iterable` of interest for which the corresponding Boolean values are `True`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp=SSP()\n",
    "ssp.read_mvp_file('Data/Oct4_slope.112m1.mvp')\n",
    "print(ssp.g[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Data/Oct4_slope.112m1.mvp\n",
    "    Opening sound speed profile data file:Data/Oct4_slope.112m1.mvp\n",
    "    [3.33333333e-02 5.00000000e-02 1.00000000e-09 1.00000000e-09\n",
    "     3.33333333e-02 1.00000000e-09 1.00000000e-09 5.00000000e-02\n",
    "     1.00000000e-09 1.70000000e-02]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B3.16 Updating the Profile\n",
    "  \n",
    "Now that we have updated the profile we need to update the sound speeds, otherwise the calculations will fail when encountering a layer that had zero sound speed gradient\n",
    "        \n",
    "        for i in range(1,len(self.g)):\n",
    "            self.proc_ss[i]=self.proc_ss[i-1]+(self.proc_depth[i] - \\\n",
    "            self.proc_depth[i-1])*self.g[i-1]\n",
    "\n",
    "***NOTE that,even though the adjustments are very small, we are inherently biasing the profile here - there are better ways of doing this, but we want to keep the time spent on this lab reasonable***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp=SSP()\n",
    "ssp.read_mvp_file('Data/Oct4_slope.112m1.mvp')\n",
    "print(ssp.proc_depth[-10:])\n",
    "print(ssp.proc_ss[-10:])\n",
    "print(ssp.g[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B4 Processing the Data - Estimating the Depth and Radial Distance Through Ray-Tracing\n",
    "\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"./Images/hor_strat.png\"><br><br>\n",
    "\n",
    "Now that we have the sound speed well conditioned and stored in a `SSP` object we are ready to start creating methods for interacting with the data. In Ocean Mapping the most common action is to determine the path of a ray using a starting depth at which the signal originated, a depression angle indicating the angle of departure and TWTT indicating the time of flight from transmission at the transducers to the seafloor and back. \n",
    "\n",
    "Given an initial beam-vector starting point (in depth) within a layered ocean as shown in the figure above, a vertically referenced depression angle, and a known two-way travel time to a bottom detection, we will now model:\n",
    "    \n",
    "    1 the depth below the starting point\n",
    "    2 the radial horizontal distance from the starting location\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B4.0 Create the `ray_trace_twtt` Method\n",
    "\n",
    "Now that we have the sound speed well conditioned and stored in a `SSP` object we are ready to start creating methods for interacting with the data.\n",
    "\n",
    "The action to be performed is usually the determination the path of a ray using a starting depth `d_start` at which the signal originates, a depression angle `th_start` indicating the angle of departure, a sound speed `ss_start` for the sound speed at the transducer at the transmission epoch and, the time of flight `twtt` indicating the time span for the signal to travel from the transmit transducer to the seafloor and on to the receive transducer. \n",
    "\n",
    "Add a method to the `SSP` class called `ray_trace_twtt()` that takes the arguments `d_start`, `th_start`, `ss_start` and `twtt`.\n",
    "\n",
    "    def ray_trace_twtt(self, d_start, th_start, ss_start, twtt):\n",
    "        pass # Remove this once you start adding code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp=SSP()\n",
    "ssp.read_mvp_file('Data/Oct4_slope.112m1.mvp')\n",
    "ssp.ray_trace_twtt(4,20*pi/180,1464,0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Data/Oct4_slope.112m1.mvp\n",
    "    Opening sound speed profile data file:Data/Oct4_slope.112m1.mvp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B4.0.0 Parameter Initialization, Part I\n",
    "\n",
    "To keep the coding a little less confusing we will do something that from a computer science point may be frowned upon, but that will make your code significantly easier to read, namely we assign the `numpy array` `SSP.proc_depth` to `d`, similarly assign the array `SSP.proc_ss` to `c` and the array `SSP.g` to `g`. This does not slow the code down by much; `c`, `d` and `g` are not copies of the data, but rather different **views** of the data i.e., no effort to allocate memory for them is needed.\n",
    "\n",
    "If you are not aware of the concept of **views** you may end up with some surprising results e.g., after assigning `c = self.proc_ss` try setting `c[-1]=0` in the method, then use `print(self.proc_ss[-1])` after calling the method - you will be rewarded with a printed value of 0! To get a **copy** that you may alter without changing the original you may use `c = self.proc_ss.copy()` instead of `c = self.proc_ss`, but this comes at the penalty of having to allocate new memory to hold the new copy. Inexperienced programmers may struggle to debug code with errors that are caused by using data views as if they are data copies.\n",
    "\n",
    "Views are a very powerful concept and effectively utilized by the `numpy` module. They allow you to pass arguments to functions and methods with a very light load (just a reference to the data, not the data itself) thus significantly speeding up execution of code. In our particular case you may think of the newly created local variables `c` and `d` as aliases for `self.proc_ss` and `self.proc_depth` \n",
    "\n",
    "    c = self.proc_ss\n",
    "    d = ...\n",
    "    g = ...\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp=SSP()\n",
    "ssp.read_mvp_file('Data/Oct4_slope.112m1.mvp')\n",
    "ssp.ray_trace_twtt(4,20*pi/180,1464,0.2)\n",
    "print(ssp.proc_ss[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Data/Oct4_slope.112m1.mvp\n",
    "    Opening sound speed profile data file:Data/Oct4_slope.112m1.mvp\n",
    "    1674.91712"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B4.0.1 Parameter Initialization, Part II\n",
    "\n",
    "This method will determine the depth and across track distance that will be reached by the signal propagating along the path determined by the input arguments. Along the way the method will determine in what layer $i$, as defined in step B3.13 the signal originated and ended up after propagating for `twtt` seconds.\n",
    "\n",
    "For this we need to initialize the parameters: `depth`, representing depth; `rad_dist`, representing across track distance; `layer_s`, representing the start or originating layer; and, `layer_e`, representing the end or final layer.\n",
    "\n",
    "We will want to initialize all these local variables with the values zero\n",
    "\n",
    "    depth=0\n",
    "    rad_dist ...\n",
    "    layer_s ...\n",
    "    layer_e ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth, rad_dist, start, stop = ssp.ray_trace_twtt(4,20*pi/180,1464,0.2)\n",
    "# depth,rad_dist,start_bin,stop_bin = ssp.determine_twtt(10,20)\n",
    "print(\"Depth           : \"+str(depth))\n",
    "print(\"Radial Distance : \"+str(rad_dist))\n",
    "print(\"Start layer     : \"+str(start))\n",
    "print(\"Stop layer      : \"+str(stop))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Depth           : 0\n",
    "    Radial Distance : 0\n",
    "    Start layer     : 0\n",
    "    Stop layer      : 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B4.0.2 Swapping the Depression Angle\n",
    "\n",
    "To keep the code simple the range of possible starting depression angles that we will allow is $\\theta_{start}$ is $[0,\\pi]$ radians ; $0$ for a signal that is transmitted horizontally to starboard, $\\pi$ for a signal traversing horizontal to port. With the right handed coordinate system with the y-axis positive to starboard that we are using this means that the across track distance is positive for $0\\le\\theta\\le\\pi/2$ and negative for  $\\pi/2\\le\\theta\\le\\pi$\n",
    "\n",
    "To avoid numerical issues in our calculations we will map the depression angle $\\theta$ to the range $[0,\\pi/2]$, given that this will swap the sign of the across track distance we need to keep track of this happening. We will set the boolean variable `swap` to `True` if this is the case and `False` otherwise.\n",
    "\n",
    "We will represent the depression angle $\\theta$  of the propagating signal by the variable `th`, and the starting depression angle $\\theta_{start}$ by `th_start`.\n",
    "\n",
    "Thus we may evaluate $\\theta_{start}$ and set `swap`\n",
    "\n",
    "    swap = False\n",
    "    if th_start < 0 or th_start > pi:\n",
    "        raise RuntimeError('SSP.ray_trace_twtt: depression angle th_start out of range')\n",
    "    elif th_start > pi/2:\n",
    "            swap = True\n",
    "            th_start = pi - th_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth, rad_dist, start, stop = ssp.ray_trace_twtt(4,0*pi/180,1464,0.2)\n",
    "# depth,rad_dist,start_bin,stop_bin = ssp.determine_twtt(10,20)\n",
    "print(\"Depth           : \"+str(depth))\n",
    "print(\"Radial Distance : \"+str(rad_dist))\n",
    "print(\"Start layer     : \"+str(start))\n",
    "print(\"Stop layer      : \"+str(stop))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Depth           : 0\n",
    "    Radial Distance : 0\n",
    "    Start layer     : 0\n",
    "    Stop layer      : 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B4.0.3 Determine the Start Layer \n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"./Images/layer_indexing.png\"><br><br>\n",
    "\n",
    "Take another look at how the indexing works for this lab. The next task at hand is the determination of the index of the depth layer in which the transmit transducer is located - for this we will assume that the layers move up and down with the sea-state i.e., the layer is purely defined by the transducer depth `d_start` with respect to the sound speed profile. \n",
    "\n",
    "The variable `layer_s` will indicate in which layer the transducer is located. Using the logic as indicated by the equation in B3.13 result in indexing as shown in the figure above. For example if `self.d[0]`==0 and `self.d[1]`== 10 and `d_start == 3` then the start layer `layer_s` == 0\n",
    "\n",
    "You saw how to use Boolean logic in step B3.15. We will take this one step further to make use of the fact that the profiles is ordered by depth and that the Boolean `False` evaluates to 0, and `True` to one. To determine the start layer you may then use:\n",
    "\n",
    "    layer_s = sum( d_start >= d) - 1\n",
    "    \n",
    "The index in the above is then simply the sum of all the layers where `d_start >= d` evaluates to `True` offset by -1. For using this kind of logic it is a prerequisite that the `d` is an ordered `iterable`, thus step B3.9 is essential.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_start=10\n",
    "depth, rad_dist, start, stop = ssp.ray_trace_twtt(d_start,20*pi/180,1464.5,0.2)\n",
    "print(\"Start depth \"+str(d_start)+\"m is contained in layer \"+str(start))\n",
    "print(\"layer \"+str(start)+\" spans the range \"+str(ssp.proc_depth[start])+\"m to \"+str(ssp.proc_depth[start+1])+\"m\" )\n",
    "\n",
    "print()\n",
    "print(\"Depth           : %.2f\"%(depth))\n",
    "print(\"Radial Distance : %.2f\"%(rad_dist))\n",
    "print(\"Start layer     : %d\"%(start))\n",
    "print(\"Stop layer      : %d\"%(stop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Start depth 10m is contained in layer 28\n",
    "    layer 28 spans the range 9.92m to 10.12m\n",
    "\n",
    "    Depth           : 0.00\n",
    "    Radial Distance : 0.00\n",
    "    Start layer     : 28\n",
    "    Stop layer      : 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B4.0.4 Determine the Ray Constant\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"./Images/steering_velocity.png\"><br><br>\n",
    "\n",
    "One of the operational problems you will face in the ray trace calculation is the fact that the sound speed at the face of the array (continuously measured and provided with each observation), may no longer match the sound speed measured at the array depth in the archived sound speed profile that you are using.\n",
    "\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"./Images/ss_mismatch.png\"><br><br>\n",
    "\n",
    "This would be because the sound speed profile was measured previously (back in time) and at a location other than the current position. The current sound speed at the transducer is in fact measured at the depth of the array –see photo to bottom left, is logged continuously and recorded together with each swath. The sonar calculates the steering angle using the current transducer sound speed. For this the **ray constant** is used, given by the equation:\n",
    "\n",
    "$$C_{ray}=\\frac{\\cos\\theta_d}{c_{start}}$$\n",
    "Where:<br>\n",
    "$C_{ray}$: Ray Constant<br>\n",
    "$\\theta_d$: Depression angle<br>\n",
    "$c_{start}$: Sound speed at transducer<br>\n",
    "\n",
    "In your `determine_depth` method calculate the ray constant `ray_c` using  `ss_start` and the depression angle `th_start`.\n",
    "\n",
    "        ray_c = cos(...)/..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_start=10\n",
    "depth, rad_dist, start, stop = ssp.ray_trace_twtt(d_start,20*pi/180,1464.5,0.2)\n",
    "print(\"Start depth \"+str(d_start)+\"m is contained in layer \"+str(start))\n",
    "print(\"layer \"+str(start)+\" spans the range \"+str(ssp.proc_depth[start])+\"m to \"+str(ssp.proc_depth[start+1])+\"m\" )\n",
    "\n",
    "print()\n",
    "print(\"Depth           : %.2f\"%(depth))\n",
    "print(\"Radial Distance : %.2f\"%(rad_dist))\n",
    "print(\"Start layer     : %d\"%(start))\n",
    "print(\"Stop layer      : %d\"%(stop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Inversion Sound Speed: 1558.49\n",
    "    Start depth 10m is contained in layer 28\n",
    "    layer 28 spans the range 9.92m to 10.12m\n",
    "\n",
    "    Depth           : 0.00\n",
    "    Radial Distance : 0.00\n",
    "    Start layer     : 28\n",
    "    Stop layer      : 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B4.0.5 Calculate Ray Path Properties for Each Layer\n",
    "\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"./Images/ray_trace.png\"><br><br>\n",
    "\n",
    "If the sound speed gradient is constant in a layer then the ray path followed by the signal through it has a constant radius of curvature i.e. *arc of circle*. The radius of curvature is then defined by the gradient as follows:\n",
    "\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"./Images/r_curvature.png\"><br><br>\n",
    "\n",
    "From the figure (***there are some errors that need to be fixed!!***) we see that (**these are the correct equations**):\n",
    "\n",
    "\n",
    "$$R_{i}=\\frac{-c_i}{g_i\\cdot \\cos\\theta_i}=-(C_{ray}\\cdot g_i)^{-1}$$<br><br>\n",
    "$$\\theta_{i}=\\arccos(c_i\\cdot C_{ray})$$<br><br>\n",
    "$$\\Delta x_i=R_i\\cdot(\\sin\\theta_{i+1}-\\sin\\theta_i)$$<br><br>\n",
    "$$\\Delta d_i=d_{i+1}-d_{i}$$<br><br>\n",
    "$$H_i=\\frac1{g_i}\\cdot \\ln \\left(\\frac{c_{i+1}}{c_i}\\right)$$<br><br>\n",
    "$$\\Delta t_i=H_i+\\frac1{g_i}\\cdot \\ln \\left( \\frac{1+\\sin\\theta_i}{1+\\sin\\theta_{i+1}}\\right)$$\n",
    "\n",
    "Where:<br>\n",
    "$i$: Index of the current layer<br>\n",
    "$R$: Radius of path curvature in layer $i$ <br>\n",
    "$\\theta_i$: Depression angle at the top of layer $i$ <br>\n",
    "$\\Delta x_i$: Radial distance traversed in layer $i$ <br>\n",
    "$\\Delta d_i$: Vertical distance traversed in layer $i$ <br>\n",
    "$H_i$: Harmonic mean sound speed multiplied by $d_i$ for layer $i$ <br>\n",
    "$\\Delta t_i$: The **one-way** travel time for traversing layer $i$ <br><br>\n",
    "the formulation of these equations means that once we know the ray constant we can now calculate the ray parameters for **all** the layers without using a for loop. This is regardless of whether the signal actually traversed through the layer!\n",
    "\n",
    "For example we can can calculate all the layer thicknesses $dz = \\Delta d$ by using:\n",
    "\n",
    "    dz = np.diff(d)\n",
    "\n",
    "In similar manner calculate all radii of curvature `r_curve`, all depression angles `th`, horizontal distances `dx`, vertical distances `dz`, Harmonic means `hm` and two way travel times `dtwtt`. Don't forget that $\\Delta t$ is the one-way travel time!\n",
    "\n",
    "Proper indexing is important here e.g., `(sin(th[1:]) - sin(th[:-1]))` calculates $\\sin\\theta_{i+1}-\\sin\\theta_i$ for all layers. Also it is important to know that the `*` operator leads to an element by element multiplication, whereas the `@` operator treats the arrays as matrices - in this case we want element-wise multiplication e.g.: `dx = r_curve * (sin(th[1:]) - sin(th[:-1]))` \n",
    "    \n",
    "    dz = ...\n",
    "    r_curve = -1 / (g[0:] * ray_c)\n",
    "    th = ...\n",
    "    dx = ... * (sin(th[1:]) - sin(th[:-1]))\n",
    "    h_m = ...*log(...)\n",
    "    dt = h_m + 2 / g * log(...)\n",
    "\n",
    "# ___\n",
    "<img align=\"left\" width=\"6%\" style=\"padding-right:10px;\" src=\"./Images/info.png\">\n",
    "\n",
    "`numpy.diff(d)` achieves the same result as `self.d[1:] - self.d[0:-1]`, this function is useful when needing to determine higher order differences e.g., `numpy.diff(self.d),2)` results in the second order difference for the array `self.d`, making code much easier to read.\n",
    "# ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_start=10\n",
    "depth, rad_dist, start, stop = ssp.ray_trace_twtt(d_start,20*pi/180,1464.5,0.2)\n",
    "print(\"Start depth \"+str(d_start)+\"m is contained in layer \"+str(start))\n",
    "print(\"layer \"+str(start)+\" spans the range \"+str(ssp.proc_depth[start])+\"m to \"+str(ssp.proc_depth[start+1])+\"m\" )\n",
    "\n",
    "print()\n",
    "print(\"Depth           : %.2f\"%(depth))\n",
    "print(\"Radial Distance : %.2f\"%(rad_dist))\n",
    "print(\"Start layer     : %d\"%(start))\n",
    "print(\"Stop layer      : %d\"%(stop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Start depth 10m is contained in layer 28\n",
    "    layer 28 spans the range 9.92m to 10.12m\n",
    "\n",
    "    Depth           : 0.00\n",
    "    Radial Distance : 0.00\n",
    "    Start layer     : 28\n",
    "    Stop layer      : 0\n",
    "\n",
    "    /home/jupyter-semmed/ESCI_OE_874/mycode/ssp.py:215: RuntimeWarning: invalid value encountered in arccos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B4.0.6 Uh-oh, why the RunTimeWarning? Calculate the Reversal Sound Speed\n",
    "\n",
    "*If everything went **well** you will encounter a warning related to the `numpy.arccos()` function when executing the code cell above* The reason this happens is that the `numpy.arccos` function is passed an argument > 1 as we will explain below this happens when the ray direction has reversed from traveling downward to upward in a layer i.e., somewhere in the layer the depression angle $\\theta$ of the ray reaches zero i.e. at the next boundary (which is never reached) $c_i\\cdot C_{ray} > 1$, the `numpy.arccos` function will return a `nan` in that case. See the example below*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=arccos(1.1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" width=\"6%\" style=\"padding-right:10px;\" src=\"./Images/info.png\"><br><br><br>\n",
    "If we transmit downwards then $\\theta_i > 0$, thus when $\\theta_i$ becomes zero it has reached a depth where the ray reverses and starts traveling upwards; this happens at sound speed $c_r$\n",
    "\n",
    "$$\\theta = 0\\Rightarrow$$<br>\n",
    "$$\\arccos(c_r\\cdot C_{ray})=0\\Rightarrow$$<br>\n",
    "$$c_r\\cdot C_{ray}=1$$<br>\n",
    "$$c_r=\\frac{1}{C_{ray}}$$\n",
    "\n",
    "Where:<br>\n",
    "$c_r$: Sound speed at which ray reversals occur<br>\n",
    "\n",
    "Add the following code to print the sound speed at which reversal occurs:\n",
    "\n",
    "    c_invert = 1/ray_c\n",
    "    print( \"Inversion Sound Speed: %.2f\"%(c_invert))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the above you may find all the layers in which ray path reversals occur for a given ray constant. When using systems for other reasons than to map the sea-floor you may not ignore this effect and need to calculate the entire ray path. Here we will not do so, as the assignment will get too expansive and we are just trying to map the sea-floor - if an reversal occurs at a given depth we will not reach the sea-floor (at least if we are using a stratified model). As we have seen, not dealing with this may result in values $c_r\\cdot C_{ray}>1$, resulting in warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_start=10\n",
    "depth, rad_dist, start, stop = ssp.ray_trace_twtt(d_start,20*pi/180,1464.5,0.2)\n",
    "print(\"Start depth \"+str(d_start)+\"m is contained in layer \"+str(start))\n",
    "print(\"layer \"+str(start)+\" spans the range \"+str(ssp.proc_depth[start])+\"m to \"+str(ssp.proc_depth[start+1])+\"m\" )\n",
    "\n",
    "print()\n",
    "print(\"Depth           : %.2f\"%(depth))\n",
    "print(\"Radial Distance : %.2f\"%(rad_dist))\n",
    "print(\"Start layer     : %d\"%(start))\n",
    "print(\"Stop layer      : %d\"%(stop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Inversion Sound Speed: 1558.49\n",
    "    Start depth 10m is contained in layer 28\n",
    "    layer 28 spans the range 9.92m to 10.12m\n",
    "\n",
    "    Depth           : 0.00\n",
    "    Radial Distance : 0.00\n",
    "    Start layer     : 28\n",
    "    Stop layer      : 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B4.0.7 Determine Properties for the First Layer\n",
    "\n",
    "In B4.0.5 we calculated the ray path properties for each layer as if the signal was traveling through. The reality is that the signal does not actually traverse through all layers. The signal originates in layer `layer_s` as determined in step B4.0.3 and will reflect of the bottom before reaching the final layer boundary. To determine the radial distance and vertical distance traversed we then need to break up the analysis in three parts:\n",
    "\n",
    "    1. The path traversed in the starting layer `layer_s`\n",
    "    2. The path traversed in the intervening layers (we already have done this in B4.0.5)\n",
    "    3. The path traversed in the final layer until `twtt` is reached.\n",
    "    \n",
    "From B4.0.5 already know how the signal traversed the intervening layers, but we must analyze the start and end layers separately. We already identified the start layer as `layer_s` and eventually must determine the end layer. To this end we will simply accumulate the two travel times from the start layer to the end layer, along with the horizontal and vertical distances. Once the accumulated TWTT exceeds the travel time `twtt` passed into the `SSP.determine_depth()` method we have reached the final layer.\n",
    "\n",
    "We will use `sum_dx`, `sum_dz`, and `sum_dt` respectively for the cumulative radial distance, vertical distance and two way travel time.\n",
    "\n",
    "To start off we will determine properties of the hypothetical path the signal would take to travel from the boundary of the start layer to the transducer located at d_start:\n",
    "\n",
    "    dx_init = r_curve[...]*(sin(...)-sin(th[...]))\n",
    "    dz_init = d_start - d[...]\n",
    "    dt_init = 2 / g[...] * log(...])\n",
    "    dt_init += 2 / g[...] * log(...)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_start=10\n",
    "depth, rad_dist, start, stop = ssp.ray_trace_twtt(d_start,20*pi/180,1464.5,0.2)\n",
    "print(\"Start depth \"+str(d_start)+\"m is contained in layer \"+str(start))\n",
    "print(\"layer \"+str(start)+\" spans the range \"+str(ssp.proc_depth[start])+\"m to \"+str(ssp.proc_depth[start+1])+\"m\" )\n",
    "\n",
    "print()\n",
    "print(\"Depth           : %.2f\"%(depth))\n",
    "print(\"Radial Distance : %.2f\"%(rad_dist))\n",
    "print(\"Start layer     : %d\"%(start))\n",
    "print(\"Stop layer      : %d\"%(stop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Inversion Sound Speed: 1558.49\n",
    "    Start depth 10m is contained in layer 28\n",
    "    layer 28 spans the range 9.92m to 10.12m\n",
    "\n",
    "    Depth           : 0.00\n",
    "    Radial Distance : 0.00\n",
    "    Start layer     : 28\n",
    "    Stop layer      : 0\n",
    "\n",
    "    /home/jupyter-semmed/ESCI_OE_874/mycode/ssp.py:215: RuntimeWarning: invalid value encountered in arccos\n",
    "      th = arccos(c[0:] * ray_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Example of How to do Math with Arrays\n",
    "\n",
    "We already know how the signal traverses the layers, we will now accumulate the contributions of these layers through the `numpy.cumsum()` function starting at the start layer. This function takes a `numpy.array` argument and returns an array of equal size with the summed elements up to the index of the element e.g,  \n",
    "\n",
    "    np.cumsum(np.ones(4))\n",
    "    \n",
    "returns the `numpy.array`: [1., 2., 3., 4.]\n",
    "\n",
    "The advantage of using the cumulative sum is that we can see what the cumulated ray properties are at the boundary of each layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example code illustrating the use of logic with numpy arrays and \n",
    "## the numpy.cumsum() function - you may use this as inspiration for the \n",
    "## implementation of the determine_depth() and determine_twtt() methods \n",
    "## of the SSP class\n",
    "## Semme J. Dijkstra\n",
    "\n",
    "# Let's have a signal that originates at d_start and ends at d_end \n",
    "# relative to d_start\n",
    "d_start = 2.1\n",
    "d_down = 3\n",
    "\n",
    "# Determine the end depth\n",
    "d_end = d_start+d_down\n",
    "\n",
    "# # Let's create a set of successive depth layers of 2m thickness\n",
    "# # mu, sigma = 2, 0.1  # mean an\n",
    "# # delta_d = np.random.normal(mu, sigma, 1000)\n",
    "delta_d = 2*np.ones(1000)\n",
    "# # Note that layers cannot have a thickness < 0\n",
    "# delta_d[delta_d < 0] = -delta_d[delta_d < 0]\n",
    "\n",
    "# # Nor can they have a thickness delta_d == 0\n",
    "# delta_d[delta_d == 0] = 2\n",
    "\n",
    "# # We can now find the depths of the boundaries using the cumulative \n",
    "# # sum. Note that we want to start at 0m\n",
    "depths = np.zeros(len(delta_d)+1)\n",
    "depths[1:] = np.cumsum(delta_d)\n",
    "\n",
    "# What layer contains the starting depth?\n",
    "layer_s = sum( d_start >= depths) - 1\n",
    "\n",
    "# The distances from the start layer to the next layers\n",
    "sum_d = np.cumsum(depths[layer_s+1:] - depths[layer_s:-1])\n",
    "\n",
    "# the distance from the start layer to the start depth \n",
    "d_init = d_start - depths[layer_s]\n",
    "\n",
    "# The total distance from d_start to all the following boundaries\n",
    "# sum_d += np.cumsum(delta_d[layer_s+1:])\n",
    "sum_d -= d_init\n",
    "\n",
    "# The number of layer boundaries the signal traverses\n",
    "n_bounds =  sum( d_down >= sum_d)\n",
    "\n",
    "# The layer that contains the depth d_end (greater than d_start i.e.,\n",
    "# with the assumption that the signal is travelling downward)\n",
    "layer_e =n_bounds+layer_s\n",
    "\n",
    "# # Note that I could also have used layer_e = sum( d_end >= depths)  - 1\n",
    "# # But you can use the same logic for the TWTTs with the way I implememted it \n",
    "\n",
    "# The distance in the end layer\n",
    "d_final = d_end - depths[layer_e]\n",
    "\n",
    "\n",
    "print(\"Signal traversed %.2fm down from starting depth of %.2fm to a total depth of %.2fm\"\\\n",
    "      %(d_down, d_start,d_start+d_down,))\n",
    "print(\"\\nStarting depth %.2fm is contained in layer %d\"%(d_start,layer_s))\n",
    "print(\"This layer ranges from %.2fm to %.2fm\"%(depths[layer_s],depths[layer_s+1]))\n",
    "print(\"\\nThe total profile depth is %.2fm\"%depths[-1])\n",
    "print(\"The profile depth from the start depth is %.2fm\"%sum_d[-1])\n",
    "print(\"\\nThe number of layer boundaries traversed: %d\"%n_bounds)\n",
    "print(\"\\nThe ending depth of %.2fm is contained in layer %d\"%(d_end,layer_e))\n",
    "print(\"This layer ranges from %.2fm to %.2fm\"%(depths[layer_e],depths[layer_e+1]))\n",
    "print(\"\\nThe distance from the start layer boundary to d_start is %.2fm\"%d_init)\n",
    "if n_bounds > 1 :\n",
    "    print(\"The distance traversed in the intervening layers is %.2fm\"%(sum_d[n_bounds-1]-d_init))\n",
    "print(\"The distance traversed in the final layer is %.2fm\"%d_final)\n",
    "if n_bounds != 0:\n",
    "    print(\"\\nTotal distance traversed is %.2fm\"%(sum_d[n_bounds-1]+d_final))\n",
    "else:\n",
    "    print(\"\\nTotal distance traversed is %.2fm\"%(d_final-d_init))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B4.0.8 Accumulate From the Start Layer\n",
    "\n",
    "In our case we want the cumulative sum of the properties of the starting layer and all successive layers (Assuming that the ray does not reverse, which we are ignoring). In the code cell above I have given an example of how you may want to address a problem like this.\n",
    "\n",
    "What we have so far is vertical distance `dz`, horizontal distance `dx`, and TWTT `dt` for each entire layer. What we will do next is to find the cumulative sums of these from the top of layer `layer_s` all the way to the end of the profile.\n",
    "\n",
    "    sum_dx = np.cumsum(dx[layer_s:])\n",
    "    sum_dt = ...\n",
    "    sum_dz = ...\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_start=10\n",
    "depth, rad_dist, start, stop = ssp.ray_trace_twtt(d_start,20*pi/180,1464.5,0.2)\n",
    "print(\"Start depth \"+str(d_start)+\"m is contained in layer \"+str(start))\n",
    "print(\"layer \"+str(start)+\" spans the range \"+str(ssp.proc_depth[start])+\"m to \"+str(ssp.proc_depth[start+1])+\"m\" )\n",
    "\n",
    "print()\n",
    "print(\"Depth           : %.2f\"%(depth))\n",
    "print(\"Radial Distance : %.2f\"%(rad_dist))\n",
    "print(\"Start layer     : %d\"%(start))\n",
    "print(\"Stop layer      : %d\"%(stop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Inversion Sound Speed: 1558.49\n",
    "    Start depth 10m is contained in layer 28\n",
    "    layer 28 spans the range 9.92m to 10.12m\n",
    "\n",
    "    Depth           : 0.00\n",
    "    Radial Distance : 0.00\n",
    "    Start layer     : 28\n",
    "    Stop layer      : 0\n",
    "\n",
    "    /home/jupyter-semmed/ESCI_OE_874/mycode/ssp.py:215: RuntimeWarning: invalid value encountered in arccos\n",
    "      th = arccos(c[0:] * ray_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B4.0.9 Offset Cumulative Sums by Values From the Start Layer\n",
    "\n",
    "We now have determined the cumulative sums of the travel time, vertical distance and, horizontal distance from the top boundary of the start layer to the boundary of all successive layers. This does not take into account the fact that the first layer was not traversed in its entirety i.e., we have to offset the cumulative sums by the values determined in step B4.0.7:\n",
    "\n",
    "    sum_dx -= ...\n",
    "    sum_dz -= ...\n",
    "    sum_dt -= ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B4.0.10  Determine the Number of Boundaries Crossed and the End Layer Index\n",
    "\n",
    "We have now determined the total accumulated TWTT `sum_dt` from the transducer to the top of each layer. Thus, we may find the layer in which the signal reaches the seafloor by comparing the TWTT `twtt` argument passed in to the method to the various `sum_dt`. The first boundary for which the `sum_dt` value exceeds `twtt` is the layer *below* which the signal reflects back. \n",
    "\n",
    "By analyzing the array `sum_dt` find the number of boundaries that the signal traversed and assign it to `n_bounds` , note that `sum_dt[-1]` will be `nan` so exclude that from your analysis:\n",
    "\n",
    "    n_bounds =  sum( twtt >= sum_dt[:-1])\n",
    "\n",
    "Now that you have determined the number of layer boundaries the signal traversed you can also determine the index the layer itself by offsetting it by the start layer `layer_s`, assign this to the variable `layer_e`\n",
    "\n",
    "    layer_e = n_bounds + layer_s \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### B4.0.11  Determine Properties for the Final Layer \n",
    "\n",
    "We now have the cumulative sums from the location of the transducer to the top of the layer in which the reflector is located e.g., the vertical distance is `sum_dz[layer_e]`. We now need to add the properties for the final layer.\n",
    "\n",
    "***\n",
    "#### B4.0.11.0  Determine Travel Time in Final Layer\n",
    "\n",
    "A problem occurs when the signal reflects in the same layer as it originates: in this lab this situation does not occur, but we will test for it and raise a `Runtimeerror` just so that if you ever use this code you are reminded of this; you can then generalize your code to deal with this issue if you want (it is not difficult, but this assignment is big enough as is).\n",
    "\n",
    "To determine this we just need to use the number of boundaries `n_bounds`, if it is zero we can throw the error, if it is not then we can determine the final two way travel time `t` as:\n",
    "\n",
    "$$twtt_{final} = TWTT - \\sum\\Delta {twtt}_{i}$$\n",
    "\n",
    "In our code $TWTT$ is represented by the argument `twtt` and the sum of the $\\Delta t$ is held by the variable `sum_dt`. Thus the code for this segment ends up being (ask yourself why the index is offset by -1):\n",
    "\n",
    "    if n_bounds >= 0:\n",
    "        t = ...-sum_dt[...-1]\n",
    "    else:\n",
    "        raise RuntimeError('SSP start depth in same layer as reflector - not yet implemented')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<img align=\"left\" width=\"6%\" style=\"padding-right:10px;\" src=\"./Images/info.png\">In this step we will be using the `numpy` tangent `tan()`, arctangent `arctan()`, hyperbolic tangent `tanh()`, and hyperbolic arctangent arctanh() functions - to make your code less verbose you can add these to the `from numpy import ...` statement at the top of your `SSP.py` file. Note here that there are arguments for doing this, the primary one being the ability to write less verbose code; and against, the primary one there that it may not be obvious to other programmers where the methods and functions used originate from.  \n",
    "___\n",
    "\n",
    "***\n",
    "        \n",
    "### B4.0.11.1  Determine Final Depression Angle $\\theta_e$, Cross Track Distance $dx_e$ and Depth $dz_e$\n",
    "\n",
    "The depression angle $\\theta_{end}$ reached at the point of reflection may then be calculated from:<br><br>\n",
    "\n",
    "$$\\theta_{end} = 2*atan\\left(tanh\\left(\\frac{-t\\cdot g_i}{4}+atanh\\left(tan\\left(\\frac{\\theta_i}{2}\\right)\\right)\\right)\\right)$$\n",
    "\n",
    "<br>***Replace division by 4 by division by 2 for one way travel times***\n",
    "\n",
    "where:<br>\n",
    "$i$: index of the final layer<br>\n",
    "$g_i$: sound speed gradient of the water mass<br>\n",
    "$t$: TWTT the signal spent traversing water mass with gradient $g_i$ from the top<br>\n",
    "$\\theta_i$: depression angle of ray at the top of layer $i$\n",
    "\n",
    "Assign the value of $\\theta_{end}$ to the variable `th_end`. Now that you have both $\\theta_{i}$ for final layer `layer_e` it is possible to calculate the cross track distance traversed to the reflector in layer `layer_e`. Similarly you may determine the vertical distance by:\n",
    "\n",
    "$$dx_{final} = R_{final}\\cdot\\left(\\cos\\theta_{end}-cos\\theta_{i}\\right)$$\n",
    "$$dz_{final} = -R_{final}\\cdot\\left(\\cos\\theta_{end}-cos\\theta_{i}\\right)$$\n",
    "\n",
    "    th_end = 2*arctan(tanh(-t * ...))\n",
    "    dx_end = ...\n",
    "    dz_end = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### B4.0.12 Determining Depth and Radial Distance\n",
    "\n",
    "Finally we get to put it altogether. The depth relative to the sonar is given by `sum_dz[n_bounds-1]+dz_end` so to get the depth `depth` relative to the water surface:\n",
    "\n",
    "    depth = sum_dz[n_bounds-1] + dz_end + ...\n",
    "    \n",
    "Similarly you may determine the cross track distance `ct_dist`; off-course, since this is transducer relative the starting offset is zero:\n",
    "\n",
    "    ct_dist = sum_dx[...] + ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### B4.0.13 Bringing it Back in Alignment:\n",
    "\n",
    "Remember that back in step B4.0.2 we made sure that the depression angle $\\theta_{start}$ was in the right domain to avoid numerical issues, but that as a result all the cross track distance are reported to starboard. We used the `swap` variable to keep track of this. The use of the variable name `swap` will hopefully make sense now that we will make use of to reverse the sign of the cross track distance if the $\\theta_{start}$ was remapped:\n",
    "\n",
    "    if swap:\n",
    "        rad_dist = -rad_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### B4.0.14 Return Results as Tuple\n",
    "\n",
    "Our final action will be to return the variables `depth`, `rad_dist`, `layer_s` and, `layer_e` as a `tuple`. Remember that Python tuples are an `iterable` that is immutable i.e., you cannot change the values. This to remind yourself and other programmers not to change these numbers.\n",
    "\n",
    "    # B4.0.14 Return Results as Tuple\n",
    "    return (depth, rad_dist, layer_s, layer_e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_start=10\n",
    "depth, rad_dist, start, stop = ssp.ray_trace_twtt(d_start,20*pi/180,1464.5,0.2)\n",
    "print(\"Start depth \"+str(d_start)+\"m is contained in layer \"+str(start))\n",
    "print(\"layer \"+str(start)+\" spans the range \"+str(ssp.proc_depth[start])+\"m to \"+str(ssp.proc_depth[start+1])+\"m\" )\n",
    "\n",
    "print()\n",
    "print(\"Depth           : %.2f\"%(depth))\n",
    "print(\"Radial Distance : %.2f\"%(rad_dist))\n",
    "print(\"Start layer     : %d\"%(start))\n",
    "print(\"Stop layer      : %d\"%(stop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Inversion Sound Speed: 1558.49\n",
    "    Start depth 10m is contained in layer 28\n",
    "    layer 28 spans the range 9.92m to 10.12m\n",
    "\n",
    "    Depth           : 59.20\n",
    "    Radial Distance : 138.23\n",
    "    Start layer     : 28\n",
    "    Stop layer      : 266\n",
    "\n",
    "    /home/jupyter-semmed/ESCI_OE_874/mycode/ssp.py:215: RuntimeWarning: invalid value encountered in arccos\n",
    "      th = arccos(c[0:] * ray_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B4.1 Calculating the TWTT for a Given Depth\n",
    "\n",
    "In the previous steps you calculated the depth and cross track distance from a given start depth, depression angle, starting sound speed and, a TWTT. Similarly you can calculate the TWTT given the terminal depth.\n",
    "\n",
    "Add the method `determine_twtt` to the `SSP` class. as follows:\n",
    "\n",
    "        def determine_twtt(self, d_start, th_start, ss_start, depth):\n",
    "        \n",
    "Now copy the contents of the the determine_depth() method up to and including step B4.0.9, but replace the statement `depth=0` from B4.01 with `dist_z = depth - d_start` i.e., the vertical distance from the transducer to the bottom downward. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B4.1.0 Initialize the TWTT\n",
    "\n",
    "Strictly speaking we do not need to initialize the TWTT. However, in order for you to evaluate the intermediate results we need a value for the TWTT that the method may return. Just to make it clear that this value is not a valid value for calculations we will set it to the `numpy` *Not a Number* value `nan`\n",
    "\n",
    "    twtt = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "d_start = 10\n",
    "th_d = 20*pi/180\n",
    "c_start = 1464.5\n",
    "twtt_in = .2\n",
    "\n",
    "# For the TWTT defined: find the depth\n",
    "depth, _, _, _ = ssp.ray_trace_twtt(d_start,th_d,c_start,twtt_in)\n",
    "print('A signal traverses from depth %.2fm in layer %d for %.2fs and reaches the bottom at %.2fm in layer %d\\n' \\\n",
    "      % (d_start,start, twtt_in, depth, stop))\n",
    "\n",
    "twtt_out, _, start, stop = ssp.determine_twtt(d_start,th_d,c_start,depth)\n",
    "print('\\nInput twtt to ray_trace_twtt(): %.2f'%(twtt_in))\n",
    "print('Resulting depth from ray_trace_twtt: %.2f'%(depth))\n",
    "print('\\nInput depth to determine_twtt(): %.2f'%(depth))\n",
    "print('Resulting twtt from determine_twtt(): %.2f'%(twtt_out))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Inversion Sound Speed: 1558.49\n",
    "    A signal traverses from depth 10.00m in layer 28 for 0.20s and reaches the bottom at 59.20m in layer 266\n",
    "    Inversion Sound Speed: 1558.49\n",
    "    Input twtt to ray_trace_twtt(): 0.20\n",
    "    Resulting depth from ray_trace_twtt: 59.20\n",
    "    Input depth to determine_twtt(): 59.20\n",
    "    Resulting twtt from determine_twtt(): nan\n",
    "\n",
    "\n",
    "    /home/jupyter-semmed/ESCI_OE_874/mycode/ssp.py:215: RuntimeWarning: invalid value encountered in arccos\n",
    "      th = arccos(c[0:] * ray_c)\n",
    "    /home/jupyter-semmed/ESCI_OE_874/mycode/ssp.py:298: RuntimeWarning: invalid value encountered in arccos\n",
    "      th = arccos(c[0:] * ray_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B4.1.1 Determine the Number of Boundaries Crossed and the End Layer Index\n",
    "\n",
    "Note that from here on in we interpret `depth` as the vertical distance from the surface to the value of the argument `depth` passed in. \n",
    "\n",
    "You have all the properties of the ray path, but we need to determine the number of boundaries that the signal passed. Start by determining the index of the layer in which the bottom is reached by e.g., using your knowledge of the thickness of each layer and assign this to the variable `layer_e`. Then simply find the number of boundaries `n_bounds` by offsetting `layer_e` with `layer_s`:\n",
    "\n",
    "    layer_e = sum(... >= np.cumsum(...))\n",
    "    n_bounds = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B4.1.2 Determine the Vertical Distance Traversed in the Last Layer\n",
    "\n",
    "Now that we know the index of the final layer we may determine the vertical distance the signal has traversed in this layer, assign this value to `dz_e`\n",
    "\n",
    "    dz_e = ... - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "###  B4.1.3 Determine the Sound Speed at the Final Depth\n",
    "\n",
    "Use the sound `c` at the last boundary passed together with last layer vertical distance `dz_e` traversed and, gradient `g` to calculate the sound speed `c_e` at the final depth.\n",
    "\n",
    "    c_e = ...+...*dz_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B4.1.4 Determine the Depression Angle $\\theta_{end}$ at the Final Depth\n",
    "\n",
    "Use the sound speed `c_end` and ray constant `ray_c` to determine the depression angle `th_e` at the end:\n",
    "\n",
    "    th_e = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B4.1.5 Determine Final Layer Two Way Travel Time\n",
    "\n",
    "Find the final layer TWTT `dt_e` by using:\n",
    "\n",
    "    dt_e = (dz_e/sin(th[layer_e]))/c[layer_e]*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B4.1.6 Determine the Total Two Way Travel Time\n",
    "\n",
    "Find the total TWTT by using the sum of the two way travel times `sum_dt` over the number of boundaries found (don't forget the -1 offset to compensate for Python starting its indexing at 0!) and the travel time `dt_e` in the final layer. At this time test whether the number of boundaries is greater than zero, as otherwise the signal originates in the same layer, a situation for which you have not created code - create a meaningful error if that is the case\n",
    "\n",
    "    if n_bounds > 0:\n",
    "        twtt = sum_dt[...]+...\n",
    "        rad_dist = sum_dx[n_bounds-1] + dx_end \n",
    "    else:\n",
    "        raise RuntimeError('SSP start depth in same layer as reflector - not yet implemented')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B4.1.7 Swap the Radial Distances\n",
    "\n",
    "See step B4.0.13\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### B4.1.8 Return Results as Tuple\n",
    "\n",
    "Our final action will be to return the variables `twtt`, `layer_s` and, `layer_e` as a `tuple`. Remember that Python tuples are an `iterable` that is immutable i.e., you cannot change the values. This to remind yourself and other programmers not to change these numbers.\n",
    "\n",
    "    # B4.1.7 Return Results as Tuple\n",
    "    return ( twtt, layer_s, layer_e)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "d_start = 10\n",
    "th_d = 20*pi/180\n",
    "c_start = 1464.5\n",
    "twtt_in = .2\n",
    "\n",
    "# For the TWTT defined: find the depth\n",
    "depth, _, _, _ = ssp.ray_trace_twtt(d_start,th_d,c_start,twtt_in)\n",
    "print('A signal traverses from depth %.2fm in layer %d for %.2fs and reaches the bottom at %.2fm in layer %d\\n' \\\n",
    "      % (d_start,start, twtt_in, depth, stop))\n",
    "\n",
    "twtt_out, _, start, stop = ssp.determine_twtt(d_start,th_d,c_start,depth)\n",
    "print('\\nInput twtt to ray_trace_twtt(): %.2f'%(twtt_in))\n",
    "print('Resulting depth from ray_trace_twtt: %.2f'%(depth))\n",
    "print('\\nInput depth to determine_twtt(): %.2f'%(depth))\n",
    "print('Resulting twtt from determine_twtt(): %.2f'%(twtt_out))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B5  Analyzing the Profiles\n",
    "\n",
    "Now that we have a method to read the mvp data files we will start processing them. The first task at hand is to create a class used to do this processing. You will find that there is a class in the `mycode` folder that is called `AnalyzeSS`, which has as its descriptor \"\"\"A Class for Analyzing Sound Speed Data\"\"\" and, for now, has one list named SSPs meant for holding `SSP` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of the files in the Data Directory - we use a brute force approach here and open any file with the .mvp\n",
    "# extension - we get away with it because the only files with that extension are the ssp data files\n",
    "\n",
    "data=Path('./Data/') # Get the path to your data folder\n",
    "ls=list(data.glob('*.mvp')) # From your data folder get a list of mvp files\n",
    "\n",
    "ana_ss = AnalyzeSS() # Create an AnalyzeSS for analysing the sound speed profiles\n",
    "    \n",
    "# Add the SSPs to ana_ss for processing\n",
    "for f in ls:\n",
    "    # Create a new SSP object for the current data file\n",
    "    ssp=SSP()\n",
    "    \n",
    "    # Read the data file into the SSP\n",
    "    ssp.read_mvp_file(str(f.resolve()))\n",
    "    \n",
    "    # Add the SSP to the AnalyzeSS object\n",
    "    ana_ss.SSPs.append(ssp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    /home/jupyter-semmed/ESCI_OE_874/Data/Oct4_slope.107m1.mvp\n",
    "    Opening sound speed profile data file:/home/jupyter-semmed/ESCI_OE_874/Data/Oct4_slope.107m1.mvp\n",
    "    /home/jupyter-semmed/ESCI_OE_874/Data/Oct4_slope.113m1.mvp\n",
    "    Opening sound speed profile data file:/home/jupyter-semmed/ESCI_OE_874/Data/Oct4_slope.113m1.mvp\n",
    "    /home/jupyter-semmed/ESCI_OE_874/Data/Oct4_slope.103m1.mvp\n",
    "    Opening sound speed profile data file:/home/jupyter-semmed/ESCI_OE_874/Data/Oct4_slope.103m1.mvp\n",
    "    /home/jupyter-semmed/ESCI_OE_874/Data/Oct4_slope.102m1.mvp\n",
    "    Opening sound speed profile data file:/home/jupyter-semmed/ESCI_OE_874/Data/Oct4_slope.102m1.mvp\n",
    "    /home/jupyter-semmed/ESCI_OE_874/Data/Oct4_slope.112m1.mvp\n",
    "    Opening sound speed profile data file:/home/jupyter-semmed/ESCI_OE_874/Data/Oct4_slope.112m1.mvp\n",
    "    /home/jupyter-semmed/ESCI_OE_874/Data/Oct4_slope.106m1.mvp\n",
    "    Opening sound speed profile data file:/home/jupyter-semmed/ESCI_OE_874/Data/Oct4_slope.106m1.mvp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the analysis we need to read create an object for all the data files of interest and add it to the list `SSPs` in `AnalyzeSS`. The code cell above achieves this in a number of steps:\n",
    "\n",
    "    data=Path('./Data/')\n",
    "    \n",
    "creates a `Path` object named data pointing to the data directory of the current working directory (the `.` operator points at the current working directory). \n",
    "\n",
    "The `glob()` method finds all the pathnames matching the pattern '\\*.mvp', where the `*` symbol is a wild card. Thus the line\n",
    "\n",
    "    ls=list(data.glob('*.mvp'))\n",
    "    \n",
    "creates a `list` named `ls` with as its members the path of all the file names ending in '.mvp' in the directory pointed at by `data`. \n",
    "\n",
    "    ana_ss = AnalyzeSS()\n",
    "    \n",
    "Creates the `AnalyzeSS` object named `ana_ss` which you will be using for the sound speed analysis.\n",
    "\n",
    "    for f in ls:\n",
    "    \n",
    "Establishes a loop that will loop through all the files pointed a by `f` in the list `ls` \n",
    "\n",
    "    ssp=SSP()\n",
    "        \n",
    "for each iteration of the loop a **new** SSP object is created.\n",
    "\n",
    "    ssp.read_mvp_file(str(f.resolve()))\n",
    "    \n",
    "Reads the data in the file pointed at by the `f` Path object. For this we need the fullpath of the file, which we find by using the `resolve()` method. Handling paths this way is nice as the `Path` will take care of the differences between operating systems e.g., the use of `/` in Linux vs `\\` in Windows.\n",
    "\n",
    "    ana_ss.SSPs.append(ssp)\n",
    "    \n",
    "Adds the newly created and initialized `SSP` object `ssp` to the list `ana_ss.SSPs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B5.0  Plotting the Profiles\n",
    "\n",
    "You probably already noticed that there is a `draw()` method in the `SSP` class; I hope you even used it out of curiosity. Please inspect the code and satisfy yourself that you understand what it does.\n",
    "\n",
    "For analysis we will want to plot all the profiles next to each other so that we may compare them. We will make use of the `SSP.draw` method here by implementing its use in the `AnalyzeSS` draw method. However, for the analysis we will want to make sure that we use the same scaling for all the plots, lest we draw invalid conclusions.\n",
    "\n",
    "Start of by adding the `draw` method to the `AnalyzeSS` class:\n",
    "\n",
    "    def draw(self):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B5.0.0  Determine the Number of Profiles to be Plotted\n",
    "\n",
    "The first thing that should be done is to determine how many profiles we should draw by counting the number of `SSP` objects in `AnalyzeSS` and assigning the number to the variable `n_ssps`\n",
    "\n",
    "    n_ssps = len(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B5.0.1 Creating the Figure\n",
    "\n",
    "The next thing that we should do is to create a figure object\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B5.0.2 Set Appropriate Scaling\n",
    "\n",
    "Now we will set the appropriate ranges for the sound speed and depth axes for *all* the `SSP` plots:\n",
    "\n",
    "    # Initialize the ranges\n",
    "    min_ss = 10000\n",
    "    max_ss = 0\n",
    "    max_dep = 0\n",
    "\n",
    "    # Update the ranges\n",
    "    for i in range(n_ssps):\n",
    "        if self.SSPs[i].proc_depth[-2] > max_dep:\n",
    "            max_dep = self.SSPs[i].proc_depth[-2]\n",
    "        if min(self.SSPs[i].proc_ss[0:-1]) < min_ss:\n",
    "            min_ss = min(self.SSPs[i].proc_ss[0:-2])\n",
    "        elif max(self.SSPs[i].proc_ss) > max_ss:\n",
    "            max_ss = max(self.SSPs[i].proc_ss[0:-2])\n",
    "\n",
    "    # Set the rannges as tuples\n",
    "    dep_range = (0, max_dep+max_dep/20)\n",
    "    ss_range = (min_ss-3,max_ss+3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B5.0.3 Create the Axes for Each SSP and Draw the Data\n",
    "\n",
    "Draw all profiles now that we can guarantee that the scaling will match:\n",
    "\n",
    "    ax = plt.subplot(1,n_ssps,1)\n",
    "    self.SSPs[0].draw(False, ax, dep_range, ss_range,True)\n",
    "    for i in range(1,n_ssps):\n",
    "        ax = plt.subplot(1,n_ssps,i+1)\n",
    "        self.SSPs[i].draw(False, ax, dep_range, ss_range, False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of the files in the Data Directory - we use a brute force approach here and open any file with the .mvp\n",
    "# extension - we get away with it because the only files with that extension are the ssp data files\n",
    "\n",
    "data=Path('./Data/') # Get the path to your data folder\n",
    "ls=list(data.glob('*.mvp')) # From your data folder get a list of mvp files\n",
    "\n",
    "ana_ss = AnalyzeSS() # Create an AnalyzeSS for analysing the sound speed profiles\n",
    "    \n",
    "# Add the SSPs to ana_ss for processing\n",
    "for f in ls:\n",
    "    # Create a new SSP object for the current data file\n",
    "    ssp=SSP()\n",
    "    \n",
    "    # Read the data file into the SSP\n",
    "    ssp.read_mvp_file(str(f.resolve()))\n",
    "    \n",
    "    # Add the SSP to the AnalyzeSS object\n",
    "    ana_ss.SSPs.append(ssp)\n",
    "    \n",
    "ana_ss.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"70%\" style=\"padding-right:10px;\" src=\"./Images/profiles.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B5.1  Quantitative Analysis of the Profiles\n",
    "\n",
    "In step B5.0 you created a draw method allowing you to look at all the profiles at the same time in consistent manner. You may use this to draw some conclusion about the profiles and the resulting differences in the measured depths. However, it would be nice to also calculate some properties and use this information to do some further analysis (again using graphs).\n",
    "\n",
    "What we will do in our analysis is to assume that one of the profiles is the right profile - and calculate the proper TWTT to the sea-floor for an entire multi-beam sonar swath i.e., a range of depression angles $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B5.1.0 Create Swath\n",
    "\n",
    "In our case we will create a swath based on an array of depression angles $\\theta$. We will have the array consist of 20 beams extending from 20<sup>o</sup> to 160<sup>o</sup>.\n",
    "\n",
    "We will have the sonar transducer located at a depth of 7m and the depth at a depth of 200m\n",
    "\n",
    "We will define the profile contained in the file  'Oct4_slope.102m1.mvp' as the 'selected' profile, that is, we will calculate depths from TWTTs from this profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = np.linspace(20, 160, 20)*pi/180\n",
    "tx_depth = 7\n",
    "depth = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### B5.1.1 Add Method to SSP to Determine c at Given Depth\n",
    "\n",
    "Add the method `determince_C` to the `SSP` class definition in `ssp.py`. Having the ability to determine the sound speed at any depth is an important feature for a class dealing with sound speed profiles. Do you think the operator at the ellipsis should be `>` or `>=`? The distinction here is immaterial as numeric value of the sound speed should be the same, only one answer is logically right. However, for other problems the distinction may be numerically significant, understanding which to use is of great value for producing code that behaves predictably. Problems caused by logical errors such as these may be exceedingly difficult to diagnose\n",
    "\n",
    "    def determine_c( self, d):\n",
    "        layer = sum( d ... self.d) - 1\n",
    "        ss = self.c[layer]+(d-self.d[layer])*self.g[layer]\n",
    "        return ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 5.1.2 Synthesize TWTTs for Given Depth\n",
    "\n",
    "We define that the profiles are free of error for their given location and epoch, thus we may use them to determine true estimates of the TWTTs.\n",
    "\n",
    "Add the method `synthesize_twtt` to the `AnalyzeSS` class for this purpose. Inspect the code carefully and convince yourself that you understand what it does:\n",
    "\n",
    "    def synthesize_twtt(self, th, tx_depth, depth):\n",
    "        n_ssps = len(self.SSPs)\n",
    "        n_beams = len(th)\n",
    "        twtt = np.zeros((n_ssps,n_beams))\n",
    "        cross_track_d = np.zeros((n_ssps,n_beams))\n",
    "        for i in range(n_ssps):\n",
    "            ss_start = self.SSPs[i].determine_c(tx_depth)\n",
    "            for j in range(n_beams):\n",
    "                twtt[i,j],cross_track_d[i,j],_,_= \\\n",
    "                    self.SSPs[i].determine_twtt(tx_depth, th[j], ss_start, depth)\n",
    "                \n",
    "        return twtt, cross_track_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Swath Function\n",
    "# the following creates the matrices twtts and true_rad_dist\n",
    "# on each row the twtt and cross track distance for each beam is held for a given profile\n",
    "\n",
    "th = np.linspace(20, 160, 20)*pi/180\n",
    "tx_depth = 7\n",
    "depth = 200\n",
    "twtts, true_rad_dist = ana_ss.synthesize_twtt(th,tx_depth,depth)\n",
    "\n",
    "n_beams = len(th)\n",
    "fig = plt.figure(figsize=(20, 5))  # Create a 20*5 plot area\n",
    "ax = plt.gca()                     # Get the current axes\n",
    "ax.set_facecolor((0, 0, 0))        # Set the background color of the plot area to black\n",
    "\n",
    "# Plot the water surface\n",
    "plt.plot((np.min(true_rad_dist),np.max(true_rad_dist)),(0,0),'b',linewidth=2)\n",
    "\n",
    "# Plot the bottom in white \n",
    "plt.plot((np.min(true_rad_dist),np.max(true_rad_dist)),(depth,depth),'w',linewidth=2)\n",
    "\n",
    "# Add the center of each beam for the first profile (as a straight line from the transducer to the bottom)\n",
    "\n",
    "for i in range(n_beams):\n",
    "    plt.plot((0,true_rad_dist[0,i]),(d_start,depth))\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.axis('equal')\n",
    "plt.xlabel('Cross Track Distance [m] →')\n",
    "plt.ylabel('← Depth [m]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"70%\" style=\"padding-right:10px;\" src=\"./Images/beams.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### B5.1.3 Select a Profile for Generating Depths from TWTTs\n",
    "\n",
    "We will want to compare the results of the ray tracing with other profiles. For this it is useful to have a `select_ssp` method be part of the `AnalyzeSS` class; allowing us to select a profile by its filename:\n",
    "\n",
    "    def select_ssp(self, file_name):\n",
    "        for i, ssp in enumerate(self.SSPs):\n",
    "            if os.path.basename(ssp.metadata['name']) == file_name:\n",
    "                return ssp, i\n",
    "            i += 1\n",
    "        return 'Not found'\n",
    "\n",
    "Note I used `enumerate` in the `for` loop - have a close look at the code to see whether you understand it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = np.linspace(20, 160, 20)*pi/180\n",
    "tx_depth = 10\n",
    "depth = 200\n",
    "twtts, true_rad_dist = ana_ss.synthesize_twtt(th,tx_depth,depth)\n",
    "ssp_name = 'Oct4_slope.102m1.mvp'\n",
    "ssp_select, n_select = ana_ss.select_ssp(ssp_name)\n",
    "c_start = ssp_select.determine_c(d_start)\n",
    "\n",
    "n_ssps =  len(ana_ss.SSPs)\n",
    "n_beams = len(th)\n",
    "model_depth = np.zeros((n_ssps,n_beams))\n",
    "model_rad_dist = np.zeros((n_ssps,n_beams))\n",
    "for i in range(n_ssps):\n",
    "    ss_start = ssp_select.determine_c(tx_depth)\n",
    "    for j in range(n_beams):\n",
    "        model_depth[i,j],model_rad_dist[i,j],_,_= ssp_select.ray_trace_twtt(tx_depth, th[j], ss_start, twtts[i,j])\n",
    "\n",
    "print( model_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    [[212.7183629  206.49902998 203.93320706 202.6243668  201.88789951\n",
    "      201.41472069 201.12606665 200.95695512 200.82861848 200.77759674\n",
    "      200.77246991 200.82861848 200.95408817 201.12606665 201.41031355\n",
    "      201.88916697 202.6243668  203.92961934 206.49902998 212.71801232]\n",
    "     [204.85164241 203.46227337 202.87597697 202.56597609 202.40527662\n",
    "      202.27553674 202.21507198 202.18943815 202.13097983 202.111522\n",
    "      202.111522   202.13097983 202.18735309 202.21507198 202.27493442\n",
    "      202.40451615 202.56597609 202.87428359 203.46227337 204.84778604]\n",
    "     ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### B5.1.4 Selecting the Results for the correct Profile\n",
    "\n",
    "In the code above we determined depths using the TWTT associated to all profiles, including the selected profile. This means that for the selected profile we expect the errors to be zero - let's check this.\n",
    "\n",
    "Note that I again used `enumerate` in the `for` loop - have another look at this code to see whether you understand how it is used here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = np.linspace(20, 160, 20)*pi/180\n",
    "tx_depth = 10\n",
    "depth = 200\n",
    "twtts, true_rad_dist = ana_ss.synthesize_twtt(th,tx_depth,depth)\n",
    "ssp_name = 'Oct4_slope.102m1.mvp'\n",
    "ssp_select, n_select = ana_ss.select_ssp(ssp_name)\n",
    "c_start = ssp_select.determine_c(d_start)\n",
    "\n",
    "n_ssps =  len(ana_ss.SSPs)\n",
    "n_beams = len(th)\n",
    "model_depth = np.zeros((n_ssps,n_beams))\n",
    "model_rad_dist = np.zeros((n_ssps,n_beams))\n",
    "for i in range(n_ssps):\n",
    "    ss_start = ssp_select.determine_c(tx_depth)\n",
    "    for j in range(n_beams):\n",
    "        model_depth[i,j],model_rad_dist[i,j],_,_= ssp_select.ray_trace_twtt(tx_depth, th[j], ss_start, twtts[i,j])\n",
    "\n",
    "\n",
    "depth_errors = model_depth - depth\n",
    "rad_dist_errors = model_rad_dist - true_rad_dist[n_select,]\n",
    "\n",
    "print(ssp_select.metadata['name'])\n",
    "print('Beam Nr   Depth error  Crosstrack error' )\n",
    "for b, d in enumerate( depth_errors[n_select]):\n",
    "    print('%4d     % .3fm       % .3fm'%(b, d, rad_dist_errors[n_select, b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Oct4_slope.102m1.mvp\n",
    "    Beam Nr   Depth error  Crosstrack error\n",
    "       0      0.000m       -0.000m\n",
    "       1      0.000m        0.000m\n",
    "       2      0.000m       -0.000m\n",
    "       3      0.000m        0.000m\n",
    "       4      0.000m        0.000m\n",
    "       5      0.000m        0.000m\n",
    "       6      0.000m        0.000m\n",
    "       7     -0.000m       -0.001m\n",
    "       8     -0.000m        0.000m\n",
    "       9      0.003m        0.000m\n",
    "      10     -0.002m        0.000m\n",
    "      11     -0.000m        0.000m\n",
    "      12     -0.000m        0.001m\n",
    "      13      0.000m        0.000m\n",
    "      14      0.000m        0.000m\n",
    "      15      0.000m        0.000m\n",
    "      16      0.000m       -0.000m\n",
    "      17      0.000m        0.000m\n",
    "      18      0.000m       -0.000m\n",
    "      19     -0.000m        0.000m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### B5.1.5 Comparing the Results to a Standard \n",
    "\n",
    "Rather than visualize inspecting the difference we can do it automatically. Here we will set a standard named `tolerance`. If the result differ by more than the tolerance we will deem to not match. However, you should ask yourself what a reasonable tolerance is. In the code cell below the tolerance is, rather arbitrarily, set to 1mm \n",
    "\n",
    "Note that we expect the results to match - the differences are purely a measure of how numerically well our methods fare. If we would see significant differences it would be time to rethink the approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = np.linspace(20, 160, 20)*pi/180\n",
    "tx_depth = 10\n",
    "depth = 200\n",
    "twtts, true_rad_dist = ana_ss.synthesize_twtt(th,tx_depth,depth)\n",
    "ssp_name = 'Oct4_slope.102m1.mvp'\n",
    "ssp_select, n_select = ana_ss.select_ssp(ssp_name)\n",
    "c_start = ssp_select.determine_c(d_start)\n",
    "\n",
    "n_ssps =  len(ana_ss.SSPs)\n",
    "n_beams = len(th)\n",
    "model_depth = np.zeros((n_ssps,n_beams))\n",
    "model_rad_dist = np.zeros((n_ssps,n_beams))\n",
    "for i in range(n_ssps):\n",
    "    ss_start = ssp_select.determine_c(tx_depth)\n",
    "    for j in range(n_beams):\n",
    "        model_depth[i,j],model_rad_dist[i,j],_,_= ssp_select.ray_trace_twtt(tx_depth, th[j], ss_start, twtts[i,j])\n",
    "\n",
    "\n",
    "depth_errors = model_depth - depth\n",
    "rad_dist_errors = model_rad_dist - true_rad_dist[n_select,]\n",
    "\n",
    "tolerance = 10**-3   # If the results differ by less than 1mm we will assign them to be a match\n",
    "\n",
    "# Test the results from the depths\n",
    "if any(abs(depth_errors[n_select,])>tolerance):\n",
    "    print(\"Results do not match!\")\n",
    "else:\n",
    "    print( \"Results match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Results do not match!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### B5.1.6 Comparing the Selected Profile With All Other Profiles\n",
    "\n",
    "It is perhaps more interesting to compare the results of the ray tracing with other profiles i.e., what does the bottom look like if we use the selected profile instead of the appropriate profile for the locations at which the profiles are obtained. In the plot below you see the resulting bottom for all the profiles. Off-course there is one set of bottom locations that do not show error (plotted in white), this is for the case where we are comparing the results for the selected profile against itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = np.linspace(20, 160, 20)*pi/180\n",
    "tx_depth = 10\n",
    "depth = 200\n",
    "twtts, true_rad_dist = ana_ss.synthesize_twtt(th,tx_depth,depth)\n",
    "ssp_name = 'Oct4_slope.102m1.mvp'\n",
    "ssp_select, n_select = ana_ss.select_ssp(ssp_name)\n",
    "c_start = ssp_select.determine_c(d_start)\n",
    "\n",
    "n_ssps =  len(ana_ss.SSPs)\n",
    "n_beams = len(th)\n",
    "model_depth = np.zeros((n_ssps,n_beams))\n",
    "model_rad_dist = np.zeros((n_ssps,n_beams))\n",
    "for i in range(n_ssps):\n",
    "    ss_start = ssp_select.determine_c(tx_depth)\n",
    "    for j in range(n_beams):\n",
    "        model_depth[i,j],model_rad_dist[i,j],_,_= ssp_select.ray_trace_twtt(tx_depth, th[j], ss_start, twtts[i,j])\n",
    "\n",
    "\n",
    "depth_errors = model_depth - depth\n",
    "rad_dist_errors = model_rad_dist - true_rad_dist[n_select,]\n",
    "\n",
    "fig = plt.figure(figsize=(20, 5))  # Create a 20*5 plot area\n",
    "ax = plt.gca()                     # Get the current axes\n",
    "ax.set_facecolor((0, 0, 0))        # Set the background color of the plot area to black\n",
    "\n",
    "# Plot the water surface\n",
    "plt.plot((np.min(true_rad_dist),np.max(true_rad_dist)),(0,0),'b',linewidth=2)\n",
    "\n",
    "# Plot all the beams and bottom segments for the selected profile\n",
    "for j in range(n_beams):\n",
    "    plt.plot((0,true_rad_dist[n_select,j]),(d_start,model_depth[n_select,j]),'w')\n",
    "\n",
    "plt.plot((true_rad_dist[n_select,0],true_rad_dist[n_select,1]), \\\n",
    "             (model_depth[n_select,0],model_depth[n_select,1]))\n",
    "\n",
    "# Create an list of colors\n",
    "\n",
    "colors = ('b','g','r','c','m','y')\n",
    "\n",
    "for i in range(n_ssps):\n",
    "    if i == n_select:\n",
    "        color = 'w'\n",
    "    else:\n",
    "        color = colors[i%6]\n",
    "    for j in range(n_beams-1):\n",
    "        plt.plot((true_rad_dist[i,j],true_rad_dist[i,j+1]), \\\n",
    "             (model_depth[i,j],model_depth[i,j+1]),color)\n",
    "\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.axis('equal')\n",
    "plt.xlabel('Cross Track Distance [m] →')\n",
    "plt.ylabel('← Depth [m]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"70%\" style=\"padding-right:10px;\" src=\"./Images/frowns.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### B5.1.7 Plotting the Errors\n",
    "\n",
    "The code in the cell above creates a plot of how the flat seafloor would show up if we used an inappropriate sound speed profile to determine depths from observed TWTTs. It is clear that there is error associated to using the wrong profile, but hard to judge what the error is.\n",
    "\n",
    "The importance of seeing the above figure is that when you are collecting data in the field and you see data that is consistently 'smiling' or 'frowning' that there is a good chance that you are using an inappropriate sound speed profile for the time and place of the survey. In the case where you have an MVP you simply make another cast, otherwise you will have to judge the level of error vs the standard that you are working to in order to decide to bring the vessel to a halt and take a sound speed cast.\n",
    "\n",
    "If we have better profiles available to us it is worthwhile evaluating what the level of error that we are inducing is. For this it is useful to compare the results of the selected profile directly to the results for the more appropriate profiles by specifically plotting the errors. The code cell given below does exactly that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = np.linspace(20, 160, 20)*pi/180\n",
    "tx_depth = 10\n",
    "depth = 200\n",
    "twtts, true_rad_dist = ana_ss.synthesize_twtt(th,tx_depth,depth)\n",
    "ssp_name = 'Oct4_slope.102m1.mvp'\n",
    "ssp_select, n_select = ana_ss.select_ssp(ssp_name)\n",
    "c_start = ssp_select.determine_c(d_start)\n",
    "\n",
    "n_ssps =  len(ana_ss.SSPs)\n",
    "n_beams = len(th)\n",
    "model_depth = np.zeros((n_ssps,n_beams))\n",
    "model_rad_dist = np.zeros((n_ssps,n_beams))\n",
    "for i in range(n_ssps):\n",
    "    ss_start = ssp_select.determine_c(tx_depth)\n",
    "    for j in range(n_beams):\n",
    "        model_depth[i,j],model_rad_dist[i,j],_,_= ssp_select.ray_trace_twtt(tx_depth, th[j], ss_start, twtts[i,j])\n",
    "\n",
    "depth_errors = model_depth - depth\n",
    "rad_dist_errors = model_rad_dist - true_rad_dist[n_select,]\n",
    "\n",
    "fig = plt.figure(figsize=(20, 15*n_ssps))  # Create a 20*5 plot area\n",
    "ax = plt.gca()                     # Get the current axes\n",
    "ax.set_facecolor((0, 0, 0))        # Set the background color of the plot area to black\n",
    "\n",
    "min_ss = 10000\n",
    "max_ss = 0\n",
    "max_dep = 0\n",
    "\n",
    "# Update the depth and sound speed ranges\n",
    "for i in range(n_ssps):\n",
    "    if ana_ss.SSPs[i].proc_depth[-2] > max_dep:\n",
    "        max_dep = ana_ss.SSPs[i].proc_depth[-2]\n",
    "    if min(ana_ss.SSPs[i].proc_ss[0:-1]) < min_ss:\n",
    "        min_ss = min(ana_ss.SSPs[i].proc_ss[0:-2])\n",
    "    elif max(ana_ss.SSPs[i].proc_ss) > max_ss:\n",
    "        max_ss = max(ana_ss.SSPs[i].proc_ss[0:-2])\n",
    "        \n",
    "# Set the rannges as tuples\n",
    "dep_range = (0, max_dep+max_dep/20)\n",
    "ss_range = (min_ss-3,max_ss+3)\n",
    "\n",
    "\n",
    "for i in range(0,n_ssps):\n",
    "    ax = plt.subplot(n_ssps*2,2,(i)*4+1)\n",
    "    ana_ss.SSPs[n_select].draw(False, ax, dep_range, ss_range, True)\n",
    "    ax = plt.subplot(n_ssps*2,2,(i)*4+2)\n",
    "    ana_ss.SSPs[i].draw(False, ax, dep_range, ss_range, False)\n",
    "    ax = plt.subplot(n_ssps*2,2,(i)*4+3)\n",
    "    plt.xlabel('Cross Track Distance [m] →')\n",
    "    plt.ylabel('Depth Error [m] →')\n",
    "    ax.title.set_text('Depth Error')\n",
    "    color = colors[i%6]\n",
    "    for j in range (n_beams-1):\n",
    "        plt.plot((true_rad_dist[i,j],true_rad_dist[i,j+1]), \\\n",
    "             (depth_errors[i,j],depth_errors[i,j+1]),color)\n",
    "    plt.ylim((np.min(depth_errors),np.max(depth_errors)))\n",
    "    \n",
    "    ax = plt.subplot(n_ssps*2,2,(i)*4+4)\n",
    "    plt.xlabel('Cross Track Distance [m] →')\n",
    "    plt.ylabel('Cross Track Error [m] →')\n",
    "    ax.title.set_text('Cross Track Error')\n",
    "    for j in range (n_beams-1):\n",
    "        plt.plot((true_rad_dist[i,j],true_rad_dist[i,j+1]), \\\n",
    "             (rad_dist_errors[i,j],rad_dist_errors[i,j+1]),color)\n",
    "    plt.ylim((np.min(rad_dist_errors),np.max(rad_dist_errors)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the plots below are for a ***different*** selected profile than the one selected in the code cell!!\n",
    "\n",
    "<img align=\"right\" width=\"70%\" style=\"padding-right:10px;\" src=\"./Images/refraction_errors.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___\n",
    "<br>\n",
    "\n",
    "<img align=\"left\" width=\"6%\" style=\"padding-right:10px;\" src=\"./Images/test.png\">\n",
    "\n",
    "# Essay Questions\n",
    "\n",
    "<br>\n",
    "Answer the questions below in essay form. Keep the answers short and concise!\n",
    "\n",
    "    1. Use the results from B5.1.7 to comment on whether the induced errors are \n",
    "       significant compared to IHO Order 1 required horizontal or vertical accuracies. \n",
    "       Note whether/how this compliance changes as a function of beam depression\n",
    "       angle.\n",
    "       \n",
    "    2. Why are the four following data fields useful for analysis of the sound \n",
    "       speed profiles? \n",
    "        1.Launch Location\n",
    "        2.Time of launch\n",
    "        3.Speed of vessel at launch\n",
    "        4.Depth at launch location\n",
    "    \n",
    "    3. Why are the duplicate records removed in reverse order in step B3.10?\n",
    "    \n",
    "    4. We extended the profiles upwards to the surface in step B3.12 assuming \n",
    "       that the water near the surface is well mixed. Would this give a problem \n",
    "       on a calm and hot sunny afternoon? Explain your answer using the \n",
    "       word 'gradient' \n",
    "\n",
    "    5. in B3.15 we replaced the zero values in the array self.g using the Boolean \n",
    "       vector `self.g == 0` in the expression self.g[self.g == 0] =  10**-9. Explain \n",
    "       in your own words what this expression does.\n",
    "       \n",
    "    6. Unless you have adapted your code to deal with ray reversal you would have \n",
    "       received a warning when determining the depression angles 𝜃𝑖 in step \n",
    "       B4.0.5 Assuming that you loaded the data contained in the file     \n",
    "       'Oct4_slope.112m1.mvp' into an SSP object 'ssp' and called the method as follows \n",
    "       'ssp.determine_depth(d_start,20*pi/180,1464.5,0.2)'\n",
    "           a. From which layer does the warning originate? How can you know?\n",
    "           b. What is the sound speed at which this occurs?\n",
    "           c. At what depth in this layer does the ray reversal occur i.e., does it go \n",
    "              from going downward to upward?\n",
    "           d. Given the location of the survey do you think a ray reversal can occur in \n",
    "              reality for this signal? \n",
    "\n",
    "     7. In B5.1.5 we looked at row `n_select` and found that some errors \n",
    "        were at the mm level. Do you think this is a significant error? In your answer\n",
    "        contemplate what a depth error a sound speed error of .1 m/s would lead to for \n",
    "        200m depths at nadir - For this you may assume that the sound speed is \n",
    "        isotropic and 1500 m/s. \n",
    "        Use the reported 'Velocity Accuracy` for the Teledyne Marine Digibar Pro to\n",
    "        illustrate how likely this level of observation error is to occur.\n",
    "        Finally, determine the level of significance of the depth errors \n",
    "        (km,hm,m,dm,cm,mm) by adjusting the `tolerance` parameter.\n",
    "        \n",
    "    8.  Using the plot of B5.1.7. (depths of 200m) what do you think will lead to a \n",
    "        generally greater improvement in positioning of bathymetry data, taking more \n",
    "        sound speed casts (coming at the cost of wear and tear on the MVP)or paying \n",
    "        for a GNSS augmentation service? To answer this question you may assume \n",
    "        that unaided GNSS (known as single point positioning) has an uncertainty of \n",
    "        approx 10m, whereas augmented GNSS can get you to cm level uncertainty.\n",
    "\n",
    "     9. Would your answer to question 8. change for very shallow water? D\n",
    "     \n",
    "    10. In B5.1.7 the errors shown are associated to a different profile than the one \n",
    "        of used in the sample code. Which profile did I use and how do you know?\n",
    "\n",
    "     Note that you are encouraged to investigate scenarios by changing the parameters in \n",
    "     this Notebook, just make sure that you can revert back to the original.        \n",
    "        \n",
    "     \n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" width=\"6%\" style=\"padding-right:10px; padding-top:10px;\" src=\"./Images/refs.png\">\n",
    "\n",
    "## Useful References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [The official Python 3.6 documentation](https://docs.python.org/3.6/index.html)\n",
    "  * [Classes](https://docs.python.org/3.6/tutorial/classes.html)\n",
    "  * [String Representation Method](https://docs.python.org/3.6/reference/datamodel.html?highlight=repr#object.__str__)\n",
    "* [Memory address](https://en.wikipedia.org/wiki/Memory_address)\n",
    "* [ePOM: Programming Basics with Python](https://github.com/hydroffice/python_basics)\n",
    "* [ePOM: Foundations of Ocean Data Science](https://github.com/hydroffice/ocean_data_science)\n",
    "* [Tools for Ocean Mapping](https://github.com/semmed/ESCI_872_Public)\n",
    "* [here](https://gpsd.gitlab.io/gpsd/NMEA.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" width=\"5%\" style=\"padding-right:10px;\" src=\"./Images/email.png\">\n",
    "\n",
    "*For issues or suggestions related to this notebook that should not be addressed on Teams, write to: semmed@ccom.unh.edu*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab B Created by John E. Hughes Clarke<br>\n",
    "Python code and Jupyter Notebook implementation by Semme J. Dijkstra"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
